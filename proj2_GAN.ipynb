{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "proj2_GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1JrfrA313MLkcjOz4_2pUl1Sc-2G2Bnbv",
      "authorship_tag": "ABX9TyOkZox1v65My9cTuZvJ+lvC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khodid/2020Evening/blob/master/proj2_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGBfc0VzAL8z",
        "colab_type": "text"
      },
      "source": [
        "# 2020 하계 프로젝트 \\#2\n",
        "- Evening 스터디 2020년 하계 방학 개인 프로젝트 \\# 2\n",
        "- 개발기간: 2020.08.07~\n",
        "- 주제: FER2013을 이용한 기초 GAN 연습\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1I2hG9pIa6v",
        "colab_type": "text"
      },
      "source": [
        "## 사전 작업 \n",
        "- Google Drive mount\n",
        "- 작업공간 디렉토리 설정\n",
        "- GPU 환경설정\n",
        "- 하이퍼파라미터 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo0Zs_XiIiaJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "9285a621-df04-4b07-8d3f-387dc1d0a096"
      },
      "source": [
        "# Google Drive Mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmFr6K1-IZt5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Working Directory\n",
        "root = '/content/gdrive/My Drive/Kaggle'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUoLmXOCK-wZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 환경설정\n",
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUeVGuEDMEq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyper-parameters\n",
        "batch_size = 64\n",
        "epochs = 400\n",
        "discriminator_learning_rate = 0.0008\n",
        "generator_learning_rate = 0.0004"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQYra-KZIW8d",
        "colab_type": "text"
      },
      "source": [
        "## Dataset 다운받기\n",
        "\n",
        "프로젝트 1에서 했던 것과 동일한 방식으로 Kaggle에서 데이터를 다운받아 주겠다.\n",
        "\n",
        "해당 코드는 프로젝트 진행하는 데 단 한 번만 실행하므로, 전부 주석처리 하였다.\n",
        "\n",
        "이번에 사용하는 데이터는 \\<FER 2013\\>, 48x48 흑백(grayscale) 이미지로서 사람이나 그림의 표정을 7가지 감정 레이블로 분류한 데이터다.\n",
        "\n",
        "Kaggle의 데이터셋 다운로드 과정은 다음과 같다. (참고자료: [Medium - How to fetch kaggle datasets into google colab](https://medium.com/analytics-vidhya/how-to-fetch-kaggle-datasets-into-google-colab-ea682569851a))\n",
        "1. kaggle.json이 존재하는 디렉토리를 등록한다.\n",
        "2. 작업 디렉토리를 변경한다.\n",
        "3. kaggle의 데이터셋 페이지에서 'Copy API Command'를 통해 다운로드 받는 명령을 가져와 실행한다.\n",
        "4. 압축을 푼다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUUrzuljKE7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 1. Config path\n",
        "# import os\n",
        "# os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4WLQITkAJse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 2. Redirect\n",
        "# %cd /content/gdrive/My Drive/Kaggle"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_RsAmn_JyVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 3. Download dataset\n",
        "# !kaggle datasets download -d msambare/fer2013"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EioidtfmNXmY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "aa2c8e07-db91-400a-a958-e76d56ada57f"
      },
      "source": [
        "### Unzip & delete zip file\n",
        "# !unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open *.zip, *.zip.zip or *.zip.ZIP.\n",
            "\n",
            "No zipfiles found.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xD0UENgNMeE",
        "colab_type": "text"
      },
      "source": [
        "## Dataset 가공하기\n",
        "\n",
        "- 교재의 spec을 그대로 따라하기 위해 28x28로 잘라서 사용할 예정.(너무 뭉게지면 그냥 48x48로 진행하겠음.\n",
        "\n",
        "\n",
        "- torchvision 패키지 사용.\n",
        " - torchvision.transforms\n",
        " - torchvision.datasets.ImageFolder\n",
        "- [torch.utils.data.DataLoader](https://pytorch.org/docs/1.1.0/_modules/torch/utils/data/dataloader.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp2IouunP7b3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "\n",
        "trans = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Grayscale(),\n",
        "    torchvision.transforms.Resize([28,28]),\n",
        "    torchvision.transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_data = torchvision.datasets.ImageFolder(root = '/content/drive/My Drive/Kaggle/fer2013/train/angry_', transform=trans)\n",
        "test_data = torchvision.datasets.ImageFolder(root='/content/drive/My Drive/Kaggle/fer2013/test/', transform=trans)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk6r0K7lRjgE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "bee66634-5125-4acf-ee1b-bb1d96343919"
      },
      "source": [
        "# peek image \n",
        "idx = 3\n",
        "from matplotlib.pyplot import imshow\n",
        "imshow(train_data[idx][0].reshape([28,28]), cmap = 'gray')\n",
        "print(train_data[idx][0][0][0])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.5098, 0.3961, 0.3529, 0.3961, 0.3922, 0.3412, 0.3176, 0.3804, 0.5255,\n",
            "        0.5059, 0.6745, 0.7255, 0.7765, 0.7412, 0.6392, 0.5098, 0.4471, 0.5098,\n",
            "        0.5686, 0.5961, 0.6039, 0.6510, 0.7137, 0.7059, 0.6471, 0.5176, 0.4000,\n",
            "        0.4941])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qE31eY2fXWbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataloader\n",
        "import torch.utils.data\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle=True, drop_last = True, num_workers=4)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size, shuffle=False,drop_last = True, num_workers=4)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsKW07_SYoW5",
        "colab_type": "text"
      },
      "source": [
        "## GAN 설계하기\n",
        "\n",
        "교재에서 keras로 구현한 모델 정의를 읽으면서 동일한 구조를 짰음.\n",
        "\n",
        "\n",
        "- 교재 GAN specification\n",
        " - ```python \n",
        "          gan = GAN(input_dim = (28,28,1)\n",
        "        , discriminator_conv_filters = [64,64,128,128]\n",
        "        , discriminator_conv_kernel_size = [5,5,5,5]\n",
        "        , discriminator_conv_strides = [2,2,2,1]\n",
        "        , discriminator_batch_norm_momentum = None\n",
        "        , discriminator_activation = 'relu'\n",
        "        , discriminator_dropout_rate = 0.4\n",
        "        , discriminator_learning_rate = 0.0008\n",
        "        , generator_initial_dense_layer_size = (7, 7, 64)\n",
        "        , generator_upsample = [2,2, 1, 1]\n",
        "        , generator_conv_filters = [128,64, 64,1]\n",
        "        , generator_conv_kernel_size = [5,5,5,5]\n",
        "        , generator_conv_strides = [1,1, 1, 1]\n",
        "        , generator_batch_norm_momentum = 0.9\n",
        "        , generator_activation = 'relu'\n",
        "        , generator_dropout_rate = None\n",
        "        , generator_learning_rate = 0.0004\n",
        "        , optimiser = 'rmsprop'\n",
        "        , z_dim = 100\n",
        "        ) \n",
        "     ```\n",
        "- Keras 참고자료\n",
        " - [교재 GAN.py](https://github.com/rickiepark/GDL_code/blob/master/models/GAN.py)\n",
        " - [교재 gan_camel_train.ipynb](https://nbviewer.jupyter.org/github/rickiepark/GDL_code/blob/master/04_01_gan_camel_train.ipynb)\n",
        "\n",
        "- 신규 함수\n",
        " - [nn.UpsamplingBilinear2d](https://pytorch.org/docs/master/generated/torch.nn.UpsamplingBilinear2d.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP-ufMZ-o_rU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "in_size = 784\n",
        "in_dim = 1\n",
        "latent_size = 100\n",
        "\n",
        "\n",
        "class GAN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(GAN, self).__init__()\n",
        "    self.discriminator = nn.Sequential(\n",
        "        # D1\n",
        "        nn.Conv2d(1, 64, kernel_size=5, stride=2, padding=2), # 1(28,28) -> 64(14,14)\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.4),\n",
        "        \n",
        "        # D2\n",
        "        nn.Conv2d(64, 64, kernel_size=5, stride=2, padding=2), # 64(14, 14) -> 64(7, 7)\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.4),\n",
        "\n",
        "        # D3\n",
        "        nn.Conv2d(64, 128, kernel_size=5, stride=2, padding=2), # 64(7, 7) ->128(4, 4)\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.4),\n",
        "\n",
        "        # D4\n",
        "        nn.Conv2d(128, 128, kernel_size=5, stride=1, padding=2), # 128(4,4) -> 128(4, 4)\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.4),\n",
        "\n",
        "        # D-end\n",
        "        nn.Flatten(), # 128*4*4 = 2048\n",
        "        nn.Linear(2048, 1), # 2048 -> 1\n",
        "        nn.Sigmoid() # 0에서 1 사이 값 하나.\n",
        "    )\n",
        "    self.generator_front = nn.Sequential(\n",
        "        # input size = (100)\n",
        "        nn.Linear(100, 3136),\n",
        "        nn.BatchNorm1d(3136),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.generator_rear = nn.Sequential(\n",
        "        # G1\n",
        "        nn.UpsamplingBilinear2d([14, 14]),\n",
        "        nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        # G2\n",
        "        nn.UpsamplingBilinear2d(28),\n",
        "        nn.Conv2d(128, 64, kernel_size=5, stride=1, padding=2),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        #G3\n",
        "        nn.ConvTranspose2d(64, 64, kernel_size=5, stride=1, padding=2), #64(28, 28)\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        #G-end\n",
        "        nn.ConvTranspose2d(64, 1, kernel_size=5, padding=2), # 1(28, 28)\n",
        "        nn.Tanh()\n",
        "    )\n",
        "  def discrim(self, x):\n",
        "    h = self.discriminator(x)\n",
        "    return h\n",
        "\n",
        "  def gener(self, z):\n",
        "    out = self.generator_front(z)\n",
        "    out = out.reshape(out.size(0), 64, 7, 7)\n",
        "    out = self.generator_rear(out)\n",
        "    return out"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fowamtzp44KC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_model = GAN().to(device)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex1DWgcbLEzQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "outputId": "051d1837-8a5f-4804-b5a2-317d986a64be"
      },
      "source": [
        "# 판별자 테스트\n",
        "test_input = (torch.rand(10, 1, 28, 28)).to(device)\n",
        "out = test_model.discrim(test_input)\n",
        "print('* 판별자 출력 확인 : ')\n",
        "print(out.shape)\n",
        "print(out)\n",
        "print()\n",
        "# 생성자 테스트\n",
        "test_z = (torch.rand(64, 100)).to(device)\n",
        "out2 = test_model.gener(test_z)\n",
        "print('* 생성자 출력 확인 : ')\n",
        "print(out2.shape)\n",
        "print(out2[0][0][0])\n",
        "printable = out2.cpu().detach().numpy()\n",
        "imshow(printable[0][0], cmap='gray')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "* 판별자 출력 확인 : \n",
            "torch.Size([10, 1])\n",
            "tensor([[0.5028],\n",
            "        [0.5034],\n",
            "        [0.5035],\n",
            "        [0.5008],\n",
            "        [0.5059],\n",
            "        [0.5006],\n",
            "        [0.4995],\n",
            "        [0.5083],\n",
            "        [0.5057],\n",
            "        [0.5032]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "\n",
            "* 생성자 출력 확인 : \n",
            "torch.Size([64, 1, 28, 28])\n",
            "tensor([0.9280, 0.9986, 0.9910, 0.9948, 0.9962, 0.9997, 1.0000, 1.0000, 1.0000,\n",
            "        0.9999, 0.9991, 0.9965, 0.9982, 0.9972, 0.9959, 0.9972, 0.9989, 0.9989,\n",
            "        0.9962, 0.9985, 0.9997, 0.9997, 0.9995, 0.9956, 0.6990, 0.9850, 0.9968,\n",
            "        0.9121], device='cuda:0', grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7eb97dcc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKrEq4TyorYu",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "\n",
        "1. 모델 선언\n",
        "2. optimizer 설정\n",
        "3. training 과정\n",
        "\n",
        "\n",
        "- 교재 모델의 설정대로 하고 있음.\n",
        " - loss function: BCE loss\n",
        " - optimizer: RMS prop\n",
        "- 참고자료\n",
        " - [GAN pytorch tutorial](https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/03-advanced/generative_adversarial_network/main.py)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XS_gHmYwX1Y9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model 선언\n",
        "model = GAN().to(device)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rapDMM4yovoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optimizer\n",
        "dis_optimizer = torch.optim.RMSprop(model.parameters(), lr = discriminator_learning_rate)  # 0.0008\n",
        "gen_optimizer = torch.optim.RMSprop(model.parameters(), lr = generator_learning_rate)      # 0.0004"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IScKgyqrYMlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss function\n",
        "criterion = nn.BCELoss()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INIIMNsiZFY6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5d16e338-958b-480e-d126-b8c99e037a0d"
      },
      "source": [
        "print('Training epochs: '+ str(epochs))\n",
        "\n",
        "data_len = len(train_loader)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for idx, (images, labels) in enumerate(train_loader):\n",
        "    images = images.to(device)\n",
        "\n",
        "    # make labels\n",
        "    real_labels = torch.ones(batch_size, 1).to(device)\n",
        "    fake_labels =  torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "    ### ======== train discriminator ========\n",
        "\n",
        "    '''실제 사진을 real로 인식하도록 loss 계산'''\n",
        "    output = model.discrim(images)\n",
        "    d_real_loss = criterion(output, real_labels)\n",
        "    real_score = output\n",
        "\n",
        "    '''가짜 사진을 fake로 인식하도록 loss 계산'''\n",
        "    z = torch.randn(batch_size, latent_size).to(device)\n",
        "    fake_images = model.gener(z)\n",
        "    output = model.discrim(fake_images)\n",
        "    d_fake_loss = criterion(output, fake_labels)\n",
        "    fake_score = output\n",
        "\n",
        "    ''' Gradient 계산, Back Propagation'''\n",
        "    d_loss = d_real_loss + d_fake_loss\n",
        "\n",
        "    dis_optimizer.zero_grad()\n",
        "    d_loss.backward()\n",
        "    dis_optimizer.step()\n",
        "\n",
        "    ### ======== train generator ========\n",
        "    ''' 가짜 이미지 생성, 평가 '''\n",
        "    z = torch.randn(batch_size, latent_size).to(device)\n",
        "    fake_images = model.gener(z)\n",
        "    output = model.discrim(fake_images)\n",
        "\n",
        "    g_loss = criterion(output, real_labels)\n",
        "\n",
        "    ''' Gradient 계산, Back Propagation '''\n",
        "    gen_optimizer.zero_grad()\n",
        "    g_loss.backward()\n",
        "    dis_optimizer.step()\n",
        "\n",
        "  print('Epoch[{}/{}] 판별자 Loss: {}, 생성자 Loss: {}'.format(epoch+1, epochs, d_loss.item(), g_loss.item()))\n",
        "\n",
        "print('훈련 끗~~!')\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training epochs: 400\n",
            "Epoch[1/400] 판별자 Loss: 0.6994189620018005, 생성자 Loss: 0.6875793933868408\n",
            "Epoch[2/400] 판별자 Loss: 0.6984118223190308, 생성자 Loss: 0.6884045600891113\n",
            "Epoch[3/400] 판별자 Loss: 0.6976439356803894, 생성자 Loss: 0.6892381906509399\n",
            "Epoch[4/400] 판별자 Loss: 0.696976363658905, 생성자 Loss: 0.6898528337478638\n",
            "Epoch[5/400] 판별자 Loss: 0.6965435147285461, 생성자 Loss: 0.6901949644088745\n",
            "Epoch[6/400] 판별자 Loss: 0.6962878108024597, 생성자 Loss: 0.6904232501983643\n",
            "Epoch[7/400] 판별자 Loss: 0.6961585283279419, 생성자 Loss: 0.6905497908592224\n",
            "Epoch[8/400] 판별자 Loss: 0.6959100961685181, 생성자 Loss: 0.6909597516059875\n",
            "Epoch[9/400] 판별자 Loss: 0.6956490874290466, 생성자 Loss: 0.6910516619682312\n",
            "Epoch[10/400] 판별자 Loss: 0.6955385208129883, 생성자 Loss: 0.6911613345146179\n",
            "Epoch[11/400] 판별자 Loss: 0.6954337358474731, 생성자 Loss: 0.6912658214569092\n",
            "Epoch[12/400] 판별자 Loss: 0.6953331232070923, 생성자 Loss: 0.6913660168647766\n",
            "Epoch[13/400] 판별자 Loss: 0.6952404975891113, 생성자 Loss: 0.6914796829223633\n",
            "Epoch[14/400] 판별자 Loss: 0.6951466798782349, 생성자 Loss: 0.6915517449378967\n",
            "Epoch[15/400] 판별자 Loss: 0.6950599551200867, 생성자 Loss: 0.6916380524635315\n",
            "Epoch[16/400] 판별자 Loss: 0.6949774026870728, 생성자 Loss: 0.6917203068733215\n",
            "Epoch[17/400] 판별자 Loss: 0.6948989629745483, 생성자 Loss: 0.6917985081672668\n",
            "Epoch[18/400] 판별자 Loss: 0.69482421875, 생성자 Loss: 0.6918730735778809\n",
            "Epoch[19/400] 판별자 Loss: 0.6948877573013306, 생성자 Loss: 0.6919440031051636\n",
            "Epoch[20/400] 판별자 Loss: 0.6946854591369629, 생성자 Loss: 0.692011296749115\n",
            "Epoch[21/400] 판별자 Loss: 0.6946209669113159, 생성자 Loss: 0.6920756101608276\n",
            "Epoch[22/400] 판별자 Loss: 0.694559633731842, 생성자 Loss: 0.692136824131012\n",
            "Epoch[23/400] 판별자 Loss: 0.6945009827613831, 생성자 Loss: 0.6921951770782471\n",
            "Epoch[24/400] 판별자 Loss: 0.6944453716278076, 생성자 Loss: 0.692250669002533\n",
            "Epoch[25/400] 판별자 Loss: 0.6943925023078918, 생성자 Loss: 0.6923034191131592\n",
            "Epoch[26/400] 판별자 Loss: 0.6943421363830566, 생성자 Loss: 0.6923536658287048\n",
            "Epoch[27/400] 판별자 Loss: 0.694294273853302, 생성자 Loss: 0.6924014687538147\n",
            "Epoch[28/400] 판별자 Loss: 0.6942485570907593, 생성자 Loss: 0.6924469470977783\n",
            "Epoch[29/400] 판별자 Loss: 0.6942057013511658, 생성자 Loss: 0.6924896240234375\n",
            "Epoch[30/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[31/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[32/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[33/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[34/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[35/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[36/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[37/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[38/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[39/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[40/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[41/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[42/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[43/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[44/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[45/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[46/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[47/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[48/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[49/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[50/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[51/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[52/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[53/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[54/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[55/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[56/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[57/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[58/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[59/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[60/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[61/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[62/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[63/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[64/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[65/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[66/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[67/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[68/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[69/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[70/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[71/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[72/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[73/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[74/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[75/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[76/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[77/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[78/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[79/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[80/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[81/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[82/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[83/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[84/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[85/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[86/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[87/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[88/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[89/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[90/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n",
            "Epoch[91/400] 판별자 Loss: 100.0, 생성자 Loss: 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-76b723058bd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# make labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-Bob72TRNZG",
        "colab_type": "text"
      },
      "source": [
        "## 생성 이미지 확인\n",
        "\n",
        "1. 랜덤 생성\n",
        "2. 가장 가까운 이미지와 비교하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WU7mJs3QAvz-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "outputId": "a4d8e92a-3662-4f65-a6ea-6411ca5bbba8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "z = torch.randn(10, 100).to(device)\n",
        "image = model.gener(z)\n",
        "\n",
        "column, row = 8, 2\n",
        "fig = plt.figure(figsize = (15,5))\n",
        "\n",
        "for i in range(1, 6):\n",
        "\n",
        "  show = image[i].cpu().detach().numpy()\n",
        "  \n",
        "  sub = fig.add_subplot(row, column, i)\n",
        "  sub.axis('off')        \n",
        "  sub.imshow(show[0])\n",
        "  sub.imshow(show[0], cmap='gray')\n",
        "\n",
        "print(show[0][0])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1.         -1.         -1.         -1.         -1.         -0.9999999\n",
            " -0.99999934 -0.99999946 -0.9999999  -0.99999994 -1.         -1.\n",
            " -1.         -1.         -1.         -1.         -1.         -1.\n",
            " -0.99999994 -0.99999994 -0.99999994 -1.         -1.         -1.\n",
            " -1.         -1.         -1.         -0.99998754]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAABnCAYAAABVTavkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAADsklEQVR4nO3dzU3jUBQG0BhIQAKxZU0HtEEzVMGSDiiDapDogAUrUEJIPKt5YxAO8NnEYzhn9ZREyZNugj7u9U9V1/UEACCxM/QGAIDxEiQAgJggAQDEBAkAICZIAAAxQQIAiO1terKqKueGbkFd11XX91Cr7VCr8VCr8VCr8XivVjoSAEBMkAAAYoIEABATJACAmCABAMQECQAgJkgAADFBAgCICRIAQEyQAABiggQAEBMkAICYIAEAxAQJACAmSAAAMUECAIgJEgBATJAAAGKCBAAQEyQAgNje0BtgOAcHB2U9n88H3AkAY6UjAQDEBAkAICZIAAAxx0j8YovFYugtADByOhIAQEyQAABiRhu/WF3XQ28BgJHTkQAAYoIEABAz2gAAWlVVtfF5HQkAICZIAAAxow0AoJXRBgDwbQQJACAmSAAAMcdIAACt1uv1xud1JACAmCABAMQECQAgJkgAADFBAgCICRIAQEyQAABiggQAEBMkAICYIAEAxAQJACDmXhsAbF1VVUNvgZ7oSAAAMUECAIgJEgBATJAAAGKCBAAQEyQAgJggAQDEBAkAICZIAAAxV7YEYOvquh56C/RERwIAiAkSAEDMaAP4MdwIiq9ofl+MWnI6EgBATJAAAGJGG8CPsbPjfyM+bzablfVisRhwJ+PmVwcAxAQJACAmSAAAsV6Okdjd3S3r9Xpd1k6naec0Nejf/v7+IJ/b9nv2N/D/c3x8XNaXl5dlfXFxMcR2fgQdCQAgJkgAALFqU+utqqpP9eUODw/Lej6fl/Vqteqwtd+jruvOc47P1opu1Kpfb0cCXUcBzdM/V6vV1mp1fX1d1ldXV2V9e3vbdQu/wjZ/V83xe/P7Z9z8Oe/VSkcCAIgJEgBArJfRBt1ol4+HWo3HNmvVPHPNSPfrtlkrN+rqxmgDAOiVIAEAxNy0C6Aj44zxMM7on44EABATJACAmCABAMQ2HiMxm83K+vn5+ds3Q246nZb1crkccCd8pHn1xeZV9vj/qBV8TEcCAIgJEgBAbOOVLSeTSXny5OSkPHh/f//6RU6n6aSPq7pNGrU6OjoqDz4+Pvbw1vzVd61OT0/Lg09PT69edH5+XtY3Nzdl/fDw0NxPp430fdOstpsgtd0Q6e24oOvn7+39m9Yul8tea3V2dlYevLu7e/Wi5jjRGPjr+vhdTafTUquXl5eub0cLV7YEAHolSAAAsY9GGwAArXQkAICYIAEAxAQJACAmSAAAMUECAIgJEgBA7A9oZ9TRABBzOgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x360 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}