{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "proj4_VAE_scenery.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNN5V/RoRu9f8SoOqRVDUva",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khodid/2020Evening/blob/master/proj4_VAE_scenery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yq-uw4xgYSrS",
        "colab_type": "text"
      },
      "source": [
        "# 처음에 시도했던 배경사진 VAE 재도전\n",
        "\n",
        "그냥 [proj3](https://github.com/khodid/2020Evening/blob/master/proj3_MNIST_VAE.ipynb)에서 성공시킨 모델 그대로 사용할 거임"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeGpUs7lYY9a",
        "colab_type": "text"
      },
      "source": [
        "## 이미지 Import\n",
        "1. Colab과 Google Drive 연결\n",
        "2. dataloader 설정\n",
        "3. 컴퓨팅 디바이스 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giDRE5GfYOI0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "c3eac362-1027-449e-fbe9-6fa13d1efdc8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDZZ4RsubSHn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "170a565a-4e08-49d2-b68a-d8820d512228"
      },
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "root = '/content/gdrive/My Drive/Kaggle/scene-classification/train-scene classification/train'\n",
        "\n",
        "trans= transforms.Compose([\n",
        "                              transforms.Resize([48, 48]),\n",
        "                              transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_data = torchvision.datasets.ImageFolder(root = root, transform= trans)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "showimg = train_data[10][0].numpy().transpose(1,2,0)\n",
        "\n",
        "plt.imshow(showimg) # train_data[순서][0: 이미지 / 1: 라벨]\n",
        "plt.axis('off')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.5, 47.5, 47.5, -0.5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Olx6TWoee7VC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.utils\n",
        "\n",
        "# dataloader 설정\n",
        "batch_size = 10\n",
        "train_set = torch.utils.data.DataLoader(train_data, batch_size= batch_size, shuffle = True, drop_last = True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDyCdPhlfRAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 디바이스 설정\n",
        "import torch.cuda\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda' : torch.cuda.manual_seed_all(777)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EMbcmqdfSTd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "81df952e-0485-4a6a-d176-8a6491473f9c"
      },
      "source": [
        "# Checking training data shape\n",
        "print(type(train_set))\n",
        "for img, label in train_set:\n",
        "  break\n",
        "print(img.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.utils.data.dataloader.DataLoader'>\n",
            "torch.Size([10, 3, 48, 48])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MdMnIlTfuoz",
        "colab_type": "text"
      },
      "source": [
        "## 모델 설정\n",
        "1. 모델 정의(기존 proj3에서 그대로 따옴)\n",
        "2. 모델 테스트\n",
        "3. 모델 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6P-1RobfYCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class VAE(nn.Module):\n",
        "  def __init__(self, latent_size):\n",
        "    super(VAE, self).__init__()\n",
        "    self.latent_size = latent_size\n",
        "    self.encoder = nn.Sequential(\n",
        "                                  # layer 1\n",
        "                                  nn.Conv2d(3, 16, kernel_size = 5, stride = 1, padding = 2), # 3(48, 48) -> 16(48, 48)\n",
        "                                  nn.BatchNorm2d(16),\n",
        "                                  nn.ReLU(),\n",
        "                                  \n",
        "                                  #layer 2\n",
        "                                  nn.Conv2d(16, 32, kernel_size = 5, stride = 2, padding=2), # 16(48, 48) -> 32(24, 24)\n",
        "                                  nn.BatchNorm2d(32),\n",
        "                                  nn.ReLU(),\n",
        "\n",
        "                                  # layer 3\n",
        "                                  nn. Conv2d(32, 32, kernel_size= 3, stride = 2, padding = 1), # 32(24, 24) -> 32(12, 12)\n",
        "                                  nn.BatchNorm2d(32),\n",
        "                                  nn.ReLU(),\n",
        "\n",
        "                                  # output layer\n",
        "                                  nn.Flatten()  # 32*12*12 = 4608\n",
        "    )\n",
        "    self.fc_mu = nn.Linear(4608, self.latent_size)\n",
        "    self.fc_logvar = nn.Linear(4608, self.latent_size)\n",
        "    self.fc_decode = nn.Linear(self.latent_size, 4608)\n",
        "    self.decoder = nn.Sequential(\n",
        "                                  # \n",
        "                                  # 3-T\n",
        "                                  nn.ConvTranspose2d(32, 32, kernel_size = 3, stride = 2, padding=1, output_padding=1),\n",
        "                                  nn.BatchNorm2d(32),\n",
        "                                  nn.LeakyReLU(),\n",
        "\n",
        "                                  # 2-T\n",
        "                                  nn.ConvTranspose2d(32, 16, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
        "                                  nn.BatchNorm2d(16),\n",
        "                                  nn.LeakyReLU(),\n",
        "\n",
        "                                  # 1-T\n",
        "                                  nn.ConvTranspose2d(16, 3, kernel_size=5, stride=1, padding=2),\n",
        "                                  nn.Sigmoid()\n",
        "    )\n",
        "  def reparameterize(self, mu, var):\n",
        "    sigma = torch.exp(0.5*var)\n",
        "    epsilon = torch.randn_like(sigma)\n",
        "    return mu + sigma * epsilon\n",
        "\n",
        "  def encode(self, img):\n",
        "    h = self.encoder(img)\n",
        "    mu, log_var = self.fc_mu(h), self.fc_logvar(h)\n",
        "    z = self.reparameterize(mu, log_var)\n",
        "    return z, mu, log_var\n",
        "\n",
        "  def decode(self, z):\n",
        "    z = self.fc_decode(z)\n",
        "    new_img = self.decoder(z.view(z.size(0), 32, 12, 12))\n",
        "    return new_img\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2iMZ5Zsfcp_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "b2983f49-cbc3-4711-8830-dfb5cf21aa8b"
      },
      "source": [
        "# model test\n",
        "with torch.no_grad():\n",
        "  input = torch.randn(20, 3, 48, 48).to(device)\n",
        "  model = VAE(latent_size = 2).to(device)\n",
        "  test_z, _, _ = model.encode(input)\n",
        "  test_out = model.decode(test_z)\n",
        "\n",
        "  print('====== ENCODER ======')\n",
        "  print(test_z.shape)\n",
        "  print('====== DECODER ======')\n",
        "  print(test_out.shape)\n",
        "\n",
        "  import matplotlib.pyplot as plt\n",
        "  if device == 'cuda': test_out = test_out.cpu()\n",
        "  show = test_out[0].view(3, 48, 48).numpy().transpose(1,2,0)\n",
        "  plt.imshow(show, cmap='gray')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====== ENCODER ======\n",
            "torch.Size([20, 2])\n",
            "====== DECODER ======\n",
            "torch.Size([20, 3, 48, 48])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFMeTiuofyKu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "23031464-b881-4198-a2e0-43f74e055bb8"
      },
      "source": [
        "model = VAE(latent_size= 35).to(device)\n",
        "model.train()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VAE(\n",
              "  (encoder): Sequential(\n",
              "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU()\n",
              "    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): ReLU()\n",
              "    (9): Flatten()\n",
              "  )\n",
              "  (fc_mu): Linear(in_features=4608, out_features=35, bias=True)\n",
              "  (fc_logvar): Linear(in_features=4608, out_features=35, bias=True)\n",
              "  (fc_decode): Linear(in_features=35, out_features=4608, bias=True)\n",
              "  (decoder): Sequential(\n",
              "    (0): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.01)\n",
              "    (3): ConvTranspose2d(32, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.01)\n",
              "    (6): ConvTranspose2d(16, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (7): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUVDf6eSfsbQ",
        "colab_type": "text"
      },
      "source": [
        "## 학습\n",
        "여기 역시 proj3에서 그대로 따옴"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbDbFw3HgWBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_function(x, target, mu, log_var):\n",
        "  x, target = x.view(-1,6912), target.view(-1, 6912) # 안 넣으면 오류남\n",
        "  # r_loss = torch.sqrt(torch.mean(torch.square(target - x)) + 1e-7) # p98 참고 # 0 되는 걸 방지하기 위해\n",
        "  r_loss = nn.functional.binary_cross_entropy(x, target, reduction='sum')\n",
        "  kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "  return r_loss, kl_div, r_loss + kl_div"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCyUF3HZo0Kl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 진행상황 모니터링용\n",
        "tags = ['Buildings', 'Forests', 'Mountains', 'Glacier', 'Street', 'Sea']\n",
        "\n",
        "def compare_img(img, new_img, label, epoch):\n",
        "  with torch.no_grad():\n",
        "    if device == 'cuda': img, new_img = img.cpu(), new_img.cpu()\n",
        "    show_original = img.view(3, 48, 48).numpy().transpose(1,2,0)\n",
        "    show_gen = new_img.view(3, 48, 48).numpy().transpose(1,2,0)\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title('original')\n",
        "    plt.imshow(show_original, cmap='gray')\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title('generated')\n",
        "    plt.imshow(show_gen, cmap = 'gray')\n",
        "    \n",
        "    plt.suptitle('Epoch: {} [label-{}]'.format(epoch, tags(label)), fontsize=16)\n",
        "    plt.savefig('VAE_scenery_train_{}.png'.format(epoch))\n",
        "\n",
        "    plt.clf() # 다음 그림 위해서 비워두기"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj9HJgAXso0E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a11c8398-bca7-4bdb-ba34-491cca393bfa"
      },
      "source": [
        "compare_img(test_out[0],test_out[1],0, 999)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgzvg8xotHSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.RMSprop(model.parameters(),lr = 0.001)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7D02op6ti4D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cc40e8b0-0b41-430b-d510-4d29ffa11a6c"
      },
      "source": [
        "lenth = len(train_set)\n",
        "print(lenth)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1702\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUmx0A6zjJES",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "\n",
        "img = img.to(device) 부분에서 \n",
        "\n",
        "> CUDA error: device-side assert triggered\n",
        "\n",
        "라는 오류가 발생했는데, [https://brstar96.github.io/shoveling/device_error_summary/](https://brstar96.github.io/shoveling/device_error_summary/)를 참고 해보니 이 문제는 복합적인 원인에 의해 일어나는 듯 했다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sNum20fKuZ5",
        "colab_type": "text"
      },
      "source": [
        "나는 다음과 같은 해결 방법을 시도해봤다.\n",
        "\n",
        "1. 런타임 유형을 CPU로 변경한다.(실패)\n",
        " - GPU 프로세싱 자체에서 문제가 발생했을 수 있다고 생각하여 런타임 유형을 GPU에서 CPU로 변경해보았다. 그 결과 새로 생성한 이미지의 값이 모두 NaN으로 출력되는 현상이 발생했다. 원인을 잘 모르겠다.\n",
        "2. batch size를 줄여본다. (부분 실패)\n",
        " - 기존 batch size가 20이었던 것을 10으로 줄여 본다.\n",
        " - 1에서 에러가 발생한 원인을 찾음. batch size가 10일 때도 **loss가 16자리, 18자리에 육박하는 큰 수**였고, loss를 전부 합하는 방식을 채택했기 때문에 batch size가 20일 땐 훨씬 큰 수였기 때문에 오류가 발생했던 것 같음. batch size를 5로 축소했을 때도 같은 문제 발생. batch_size\\*3\\*64\\*64 개의 loss의 총합을 구하는 것 자체가 너무 큰 것 같아서 이미지 사이즈 자체를 좀더 줄여보기로 함.\n",
        "3. 이미지 크기를 줄여 본다.\n",
        "  - 기존 3X64X64로 줄였던 것을 3X48X48로 다시 한 번 축소. 이미지의 형상을 알아보는 데엔 무리가 없음.\n",
        "  - 3X64X64 =12288 --> 3X48X48=6912 로 계산해야 할 데이터량을 절반으로 줄임. loss 값도 4만 대로 연산 가능한 숫자로 확 줄어든 것을 관찰할 수 있었음."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CAF0gnetkq8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dd199c73-7a92-40bf-9aaf-d8df9c4330cf"
      },
      "source": [
        "epochs = 50\n",
        "tick = [0, 5, 8, 10, 15, 20, 30, 50, 100, 120, 150, 180, 200]\n",
        "\n",
        "model.train(True)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for idx, (img, label) in enumerate(train_set):\n",
        "    img = img.to(device)\n",
        "    \n",
        "    z, mu, var = model.encode(img)\n",
        "    new_img = model.decode(z)\n",
        "    r, k, loss = loss_function(new_img, img, mu, var)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (idx+1) % 20 is 0 : print('Epoch [{}/{}] Step [{}/{}] loss: {} rmse: {}, kl_div: {}'.format(epoch+1, epochs, idx+1, lenth, loss.item(), r.item(), k.item()))\n",
        "  if epoch in tick : compare_img(img[0], new_img[0], label[0], epoch)\n",
        "compare_img(img[0], new_img[0], label[0], epoch+1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/50] Step [20/1702] loss: 45152.0390625 rmse: 42260.5546875, kl_div: 2891.484375\n",
            "Epoch [1/50] Step [40/1702] loss: 45869.8203125 rmse: 42979.47265625, kl_div: 2890.346923828125\n",
            "Epoch [1/50] Step [60/1702] loss: 44805.80078125 rmse: 41962.8828125, kl_div: 2842.91845703125\n",
            "Epoch [1/50] Step [80/1702] loss: 47789.2890625 rmse: 44580.96484375, kl_div: 3208.32470703125\n",
            "Epoch [1/50] Step [100/1702] loss: 46082.953125 rmse: 43140.2421875, kl_div: 2942.708984375\n",
            "Epoch [1/50] Step [120/1702] loss: 44980.4765625 rmse: 42690.5234375, kl_div: 2289.953369140625\n",
            "Epoch [1/50] Step [140/1702] loss: 45173.51171875 rmse: 42681.96875, kl_div: 2491.54345703125\n",
            "Epoch [1/50] Step [160/1702] loss: 45724.8359375 rmse: 42868.01171875, kl_div: 2856.82568359375\n",
            "Epoch [1/50] Step [180/1702] loss: 46077.35546875 rmse: 42920.35546875, kl_div: 3156.998291015625\n",
            "Epoch [1/50] Step [200/1702] loss: 45383.47265625 rmse: 42638.58203125, kl_div: 2744.890625\n",
            "Epoch [1/50] Step [220/1702] loss: 50438.8515625 rmse: 47365.17578125, kl_div: 3073.677490234375\n",
            "Epoch [1/50] Step [240/1702] loss: 45239.765625 rmse: 42907.59375, kl_div: 2332.170654296875\n",
            "Epoch [1/50] Step [260/1702] loss: 44078.75 rmse: 41260.3671875, kl_div: 2818.3828125\n",
            "Epoch [1/50] Step [280/1702] loss: 44880.22265625 rmse: 42601.0390625, kl_div: 2279.182373046875\n",
            "Epoch [1/50] Step [300/1702] loss: 1151221.0 rmse: 49451.49609375, kl_div: 1101769.5\n",
            "Epoch [1/50] Step [320/1702] loss: 43053.91015625 rmse: 40482.703125, kl_div: 2571.207763671875\n",
            "Epoch [1/50] Step [340/1702] loss: 43892.0078125 rmse: 41107.35546875, kl_div: 2784.650390625\n",
            "Epoch [1/50] Step [360/1702] loss: 41569.70703125 rmse: 39145.02734375, kl_div: 2424.68115234375\n",
            "Epoch [1/50] Step [380/1702] loss: 44223.578125 rmse: 42137.6796875, kl_div: 2085.89990234375\n",
            "Epoch [1/50] Step [400/1702] loss: 40935.4140625 rmse: 38592.84375, kl_div: 2342.571044921875\n",
            "Epoch [1/50] Step [420/1702] loss: 43617.53515625 rmse: 41091.953125, kl_div: 2525.5830078125\n",
            "Epoch [1/50] Step [440/1702] loss: 42629.60546875 rmse: 40221.6796875, kl_div: 2407.926513671875\n",
            "Epoch [1/50] Step [460/1702] loss: 44934.55078125 rmse: 42808.421875, kl_div: 2126.12939453125\n",
            "Epoch [1/50] Step [480/1702] loss: 43371.06640625 rmse: 41311.265625, kl_div: 2059.7998046875\n",
            "Epoch [1/50] Step [500/1702] loss: 46211.67578125 rmse: 44140.609375, kl_div: 2071.064697265625\n",
            "Epoch [1/50] Step [520/1702] loss: 42784.1640625 rmse: 40132.87890625, kl_div: 2651.28662109375\n",
            "Epoch [1/50] Step [540/1702] loss: 44117.02734375 rmse: 41177.26953125, kl_div: 2939.7568359375\n",
            "Epoch [1/50] Step [560/1702] loss: 43110.2421875 rmse: 40412.515625, kl_div: 2697.728271484375\n",
            "Epoch [1/50] Step [580/1702] loss: 44020.94921875 rmse: 40915.8984375, kl_div: 3105.05078125\n",
            "Epoch [1/50] Step [600/1702] loss: 43264.00390625 rmse: 41121.8515625, kl_div: 2142.1533203125\n",
            "Epoch [1/50] Step [620/1702] loss: 42198.203125 rmse: 39912.7109375, kl_div: 2285.49169921875\n",
            "Epoch [1/50] Step [640/1702] loss: 43683.78515625 rmse: 40323.8671875, kl_div: 3359.91943359375\n",
            "Epoch [1/50] Step [660/1702] loss: 43431.40234375 rmse: 41042.51953125, kl_div: 2388.8837890625\n",
            "Epoch [1/50] Step [680/1702] loss: 43111.1328125 rmse: 40877.7734375, kl_div: 2233.3603515625\n",
            "Epoch [1/50] Step [700/1702] loss: 42933.41796875 rmse: 40913.125, kl_div: 2020.29296875\n",
            "Epoch [1/50] Step [720/1702] loss: 44112.7265625 rmse: 41570.625, kl_div: 2542.10302734375\n",
            "Epoch [1/50] Step [740/1702] loss: 45436.765625 rmse: 42674.7890625, kl_div: 2761.97509765625\n",
            "Epoch [1/50] Step [760/1702] loss: 45395.93359375 rmse: 42871.8984375, kl_div: 2524.03369140625\n",
            "Epoch [1/50] Step [780/1702] loss: 46444.73828125 rmse: 43542.5234375, kl_div: 2902.21337890625\n",
            "Epoch [1/50] Step [800/1702] loss: 44460.296875 rmse: 41794.68359375, kl_div: 2665.615234375\n",
            "Epoch [1/50] Step [820/1702] loss: 46982.20703125 rmse: 43231.2265625, kl_div: 3750.98046875\n",
            "Epoch [1/50] Step [840/1702] loss: 41984.671875 rmse: 39480.9921875, kl_div: 2503.67822265625\n",
            "Epoch [1/50] Step [860/1702] loss: 44731.9921875 rmse: 42316.8203125, kl_div: 2415.1728515625\n",
            "Epoch [1/50] Step [880/1702] loss: 43141.63671875 rmse: 40835.1171875, kl_div: 2306.52001953125\n",
            "Epoch [1/50] Step [900/1702] loss: 43024.65234375 rmse: 40994.421875, kl_div: 2030.230224609375\n",
            "Epoch [1/50] Step [920/1702] loss: 43721.515625 rmse: 41409.8203125, kl_div: 2311.6962890625\n",
            "Epoch [1/50] Step [940/1702] loss: 43543.3125 rmse: 41268.625, kl_div: 2274.68798828125\n",
            "Epoch [1/50] Step [960/1702] loss: 43096.484375 rmse: 41020.9765625, kl_div: 2075.508544921875\n",
            "Epoch [1/50] Step [980/1702] loss: 43225.14453125 rmse: 40735.12890625, kl_div: 2490.015380859375\n",
            "Epoch [1/50] Step [1000/1702] loss: 43760.9375 rmse: 41532.06640625, kl_div: 2228.86962890625\n",
            "Epoch [1/50] Step [1020/1702] loss: 41034.6171875 rmse: 38749.3984375, kl_div: 2285.22021484375\n",
            "Epoch [1/50] Step [1040/1702] loss: 44175.4140625 rmse: 41469.32421875, kl_div: 2706.091796875\n",
            "Epoch [1/50] Step [1060/1702] loss: 43736.125 rmse: 41316.06640625, kl_div: 2420.0576171875\n",
            "Epoch [1/50] Step [1080/1702] loss: 45054.94140625 rmse: 41670.40234375, kl_div: 3384.53759765625\n",
            "Epoch [1/50] Step [1100/1702] loss: 43818.3515625 rmse: 41931.84765625, kl_div: 1886.5050048828125\n",
            "Epoch [1/50] Step [1120/1702] loss: 44338.09375 rmse: 41748.69140625, kl_div: 2589.403076171875\n",
            "Epoch [1/50] Step [1140/1702] loss: 42197.58203125 rmse: 40064.0390625, kl_div: 2133.54248046875\n",
            "Epoch [1/50] Step [1160/1702] loss: 40806.86328125 rmse: 38530.421875, kl_div: 2276.44287109375\n",
            "Epoch [1/50] Step [1180/1702] loss: 45460.73828125 rmse: 43284.0546875, kl_div: 2176.683349609375\n",
            "Epoch [1/50] Step [1200/1702] loss: 41436.41796875 rmse: 39457.140625, kl_div: 1979.277099609375\n",
            "Epoch [1/50] Step [1220/1702] loss: 42112.046875 rmse: 40263.734375, kl_div: 1848.314208984375\n",
            "Epoch [1/50] Step [1240/1702] loss: 45612.71875 rmse: 42340.33203125, kl_div: 3272.3876953125\n",
            "Epoch [1/50] Step [1260/1702] loss: 45018.359375 rmse: 42954.99609375, kl_div: 2063.3642578125\n",
            "Epoch [1/50] Step [1280/1702] loss: 44684.5625 rmse: 42381.07421875, kl_div: 2303.490234375\n",
            "Epoch [1/50] Step [1300/1702] loss: 43101.8125 rmse: 40372.78515625, kl_div: 2729.02587890625\n",
            "Epoch [1/50] Step [1320/1702] loss: 43489.9296875 rmse: 41137.84375, kl_div: 2352.087158203125\n",
            "Epoch [1/50] Step [1340/1702] loss: 43114.80859375 rmse: 40971.0, kl_div: 2143.80859375\n",
            "Epoch [1/50] Step [1360/1702] loss: 42156.484375 rmse: 40313.08203125, kl_div: 1843.4013671875\n",
            "Epoch [1/50] Step [1380/1702] loss: 45174.828125 rmse: 42804.9140625, kl_div: 2369.91455078125\n",
            "Epoch [1/50] Step [1400/1702] loss: 43178.57421875 rmse: 40744.7578125, kl_div: 2433.81640625\n",
            "Epoch [1/50] Step [1420/1702] loss: 47227.47265625 rmse: 44072.26953125, kl_div: 3155.203125\n",
            "Epoch [1/50] Step [1440/1702] loss: 45456.47265625 rmse: 43259.75, kl_div: 2196.720947265625\n",
            "Epoch [1/50] Step [1460/1702] loss: 41249.27734375 rmse: 38851.01953125, kl_div: 2398.2587890625\n",
            "Epoch [1/50] Step [1480/1702] loss: 42977.97265625 rmse: 40143.6171875, kl_div: 2834.3564453125\n",
            "Epoch [1/50] Step [1500/1702] loss: 42165.7109375 rmse: 39977.0703125, kl_div: 2188.64111328125\n",
            "Epoch [1/50] Step [1520/1702] loss: 44195.51953125 rmse: 41969.40625, kl_div: 2226.11328125\n",
            "Epoch [1/50] Step [1540/1702] loss: 42182.55859375 rmse: 40287.3359375, kl_div: 1895.220947265625\n",
            "Epoch [1/50] Step [1560/1702] loss: 43074.1640625 rmse: 40822.8671875, kl_div: 2251.2958984375\n",
            "Epoch [1/50] Step [1580/1702] loss: 46516.24609375 rmse: 44186.1171875, kl_div: 2330.128173828125\n",
            "Epoch [1/50] Step [1600/1702] loss: 44391.875 rmse: 41944.640625, kl_div: 2447.236328125\n",
            "Epoch [1/50] Step [1620/1702] loss: 42149.53515625 rmse: 40051.71875, kl_div: 2097.817626953125\n",
            "Epoch [1/50] Step [1640/1702] loss: 44072.83203125 rmse: 41077.2578125, kl_div: 2995.572998046875\n",
            "Epoch [1/50] Step [1660/1702] loss: 39685.890625 rmse: 37245.4921875, kl_div: 2440.39990234375\n",
            "Epoch [1/50] Step [1680/1702] loss: 45872.25 rmse: 43205.765625, kl_div: 2666.48388671875\n",
            "Epoch [1/50] Step [1700/1702] loss: 43870.76171875 rmse: 41585.30078125, kl_div: 2285.46240234375\n",
            "Epoch [2/50] Step [20/1702] loss: 46780.84765625 rmse: 43685.7890625, kl_div: 3095.06005859375\n",
            "Epoch [2/50] Step [40/1702] loss: 41834.98046875 rmse: 39438.203125, kl_div: 2396.7763671875\n",
            "Epoch [2/50] Step [60/1702] loss: 44935.14453125 rmse: 42557.953125, kl_div: 2377.190185546875\n",
            "Epoch [2/50] Step [80/1702] loss: 43347.7421875 rmse: 40925.8671875, kl_div: 2421.87353515625\n",
            "Epoch [2/50] Step [100/1702] loss: 42819.421875 rmse: 40036.1015625, kl_div: 2783.322265625\n",
            "Epoch [2/50] Step [120/1702] loss: 42477.0703125 rmse: 39661.98046875, kl_div: 2815.08837890625\n",
            "Epoch [2/50] Step [140/1702] loss: 42503.953125 rmse: 39997.78125, kl_div: 2506.17333984375\n",
            "Epoch [2/50] Step [160/1702] loss: 45166.1953125 rmse: 42528.4453125, kl_div: 2637.75146484375\n",
            "Epoch [2/50] Step [180/1702] loss: 44111.37109375 rmse: 41929.6015625, kl_div: 2181.7705078125\n",
            "Epoch [2/50] Step [200/1702] loss: 41981.984375 rmse: 39661.2421875, kl_div: 2320.744140625\n",
            "Epoch [2/50] Step [220/1702] loss: 42359.09375 rmse: 40101.015625, kl_div: 2258.080078125\n",
            "Epoch [2/50] Step [240/1702] loss: 42361.3046875 rmse: 40037.953125, kl_div: 2323.35205078125\n",
            "Epoch [2/50] Step [260/1702] loss: 44031.24609375 rmse: 41446.6875, kl_div: 2584.5576171875\n",
            "Epoch [2/50] Step [280/1702] loss: 46000.3984375 rmse: 43270.8203125, kl_div: 2729.576171875\n",
            "Epoch [2/50] Step [300/1702] loss: 45716.8984375 rmse: 43344.73828125, kl_div: 2372.1611328125\n",
            "Epoch [2/50] Step [320/1702] loss: 45203.61328125 rmse: 41627.6796875, kl_div: 3575.933837890625\n",
            "Epoch [2/50] Step [340/1702] loss: 43568.62109375 rmse: 40843.3828125, kl_div: 2725.2373046875\n",
            "Epoch [2/50] Step [360/1702] loss: 44861.90625 rmse: 41855.1796875, kl_div: 3006.726806640625\n",
            "Epoch [2/50] Step [380/1702] loss: 47790.30078125 rmse: 45006.4921875, kl_div: 2783.80810546875\n",
            "Epoch [2/50] Step [400/1702] loss: 42513.99609375 rmse: 39903.3984375, kl_div: 2610.59912109375\n",
            "Epoch [2/50] Step [420/1702] loss: 42316.55859375 rmse: 39746.671875, kl_div: 2569.8857421875\n",
            "Epoch [2/50] Step [440/1702] loss: 44927.34375 rmse: 42027.55859375, kl_div: 2899.78515625\n",
            "Epoch [2/50] Step [460/1702] loss: 44296.46875 rmse: 41549.6796875, kl_div: 2746.7900390625\n",
            "Epoch [2/50] Step [480/1702] loss: 42776.7578125 rmse: 40376.5546875, kl_div: 2400.2041015625\n",
            "Epoch [2/50] Step [500/1702] loss: 42054.828125 rmse: 39491.7265625, kl_div: 2563.103515625\n",
            "Epoch [2/50] Step [520/1702] loss: 41380.328125 rmse: 39333.6015625, kl_div: 2046.7281494140625\n",
            "Epoch [2/50] Step [540/1702] loss: 47433.5703125 rmse: 43271.4140625, kl_div: 4162.1572265625\n",
            "Epoch [2/50] Step [560/1702] loss: 41814.61328125 rmse: 39471.1953125, kl_div: 2343.416259765625\n",
            "Epoch [2/50] Step [580/1702] loss: 43729.55078125 rmse: 40983.3203125, kl_div: 2746.22998046875\n",
            "Epoch [2/50] Step [600/1702] loss: 43471.5 rmse: 41005.08203125, kl_div: 2466.41748046875\n",
            "Epoch [2/50] Step [620/1702] loss: 43518.25390625 rmse: 41344.99609375, kl_div: 2173.257080078125\n",
            "Epoch [2/50] Step [640/1702] loss: 46784.828125 rmse: 43639.6328125, kl_div: 3145.195556640625\n",
            "Epoch [2/50] Step [660/1702] loss: 44552.7578125 rmse: 41456.55078125, kl_div: 3096.208251953125\n",
            "Epoch [2/50] Step [680/1702] loss: 46118.11328125 rmse: 42889.99609375, kl_div: 3228.116455078125\n",
            "Epoch [2/50] Step [700/1702] loss: 42303.3203125 rmse: 40005.8125, kl_div: 2297.50634765625\n",
            "Epoch [2/50] Step [720/1702] loss: 45159.09375 rmse: 42789.40625, kl_div: 2369.6884765625\n",
            "Epoch [2/50] Step [740/1702] loss: 43723.0625 rmse: 41415.1328125, kl_div: 2307.928466796875\n",
            "Epoch [2/50] Step [760/1702] loss: 44265.91015625 rmse: 42034.6796875, kl_div: 2231.230224609375\n",
            "Epoch [2/50] Step [780/1702] loss: 42178.7734375 rmse: 39310.5390625, kl_div: 2868.234130859375\n",
            "Epoch [2/50] Step [800/1702] loss: 43694.1015625 rmse: 40830.9921875, kl_div: 2863.107666015625\n",
            "Epoch [2/50] Step [820/1702] loss: 44701.82421875 rmse: 41901.48828125, kl_div: 2800.337646484375\n",
            "Epoch [2/50] Step [840/1702] loss: 43579.8046875 rmse: 40899.9609375, kl_div: 2679.844970703125\n",
            "Epoch [2/50] Step [860/1702] loss: 40912.796875 rmse: 38633.09375, kl_div: 2279.701904296875\n",
            "Epoch [2/50] Step [880/1702] loss: 43599.6328125 rmse: 41025.765625, kl_div: 2573.8671875\n",
            "Epoch [2/50] Step [900/1702] loss: 45124.07421875 rmse: 42005.26953125, kl_div: 3118.806396484375\n",
            "Epoch [2/50] Step [920/1702] loss: 43486.61328125 rmse: 40860.3046875, kl_div: 2626.30712890625\n",
            "Epoch [2/50] Step [940/1702] loss: 43673.79296875 rmse: 41041.1484375, kl_div: 2632.64306640625\n",
            "Epoch [2/50] Step [960/1702] loss: 43021.875 rmse: 39656.34375, kl_div: 3365.529296875\n",
            "Epoch [2/50] Step [980/1702] loss: 44732.0859375 rmse: 42226.83203125, kl_div: 2505.252197265625\n",
            "Epoch [2/50] Step [1000/1702] loss: 43455.30078125 rmse: 40949.94140625, kl_div: 2505.359375\n",
            "Epoch [2/50] Step [1020/1702] loss: 45242.53515625 rmse: 42307.8359375, kl_div: 2934.699951171875\n",
            "Epoch [2/50] Step [1040/1702] loss: 45060.88671875 rmse: 42042.78125, kl_div: 3018.10546875\n",
            "Epoch [2/50] Step [1060/1702] loss: 45890.46875 rmse: 42813.453125, kl_div: 3077.0166015625\n",
            "Epoch [2/50] Step [1080/1702] loss: 50227.79296875 rmse: 42776.19921875, kl_div: 7451.5927734375\n",
            "Epoch [2/50] Step [1100/1702] loss: 43988.9140625 rmse: 41127.109375, kl_div: 2861.80322265625\n",
            "Epoch [2/50] Step [1120/1702] loss: 44011.41015625 rmse: 41343.7421875, kl_div: 2667.66845703125\n",
            "Epoch [2/50] Step [1140/1702] loss: 45347.14453125 rmse: 41991.52734375, kl_div: 3355.617431640625\n",
            "Epoch [2/50] Step [1160/1702] loss: 45065.734375 rmse: 42437.1953125, kl_div: 2628.53857421875\n",
            "Epoch [2/50] Step [1180/1702] loss: 43651.0390625 rmse: 40468.25, kl_div: 3182.7900390625\n",
            "Epoch [2/50] Step [1200/1702] loss: 43231.91015625 rmse: 40759.65625, kl_div: 2472.254638671875\n",
            "Epoch [2/50] Step [1220/1702] loss: 44408.56640625 rmse: 41459.12109375, kl_div: 2949.4462890625\n",
            "Epoch [2/50] Step [1240/1702] loss: 42228.33984375 rmse: 38788.48828125, kl_div: 3439.85107421875\n",
            "Epoch [2/50] Step [1260/1702] loss: 42806.359375 rmse: 39590.79296875, kl_div: 3215.564453125\n",
            "Epoch [2/50] Step [1280/1702] loss: 42986.8203125 rmse: 39487.9375, kl_div: 3498.882568359375\n",
            "Epoch [2/50] Step [1300/1702] loss: 43654.5234375 rmse: 41034.328125, kl_div: 2620.19384765625\n",
            "Epoch [2/50] Step [1320/1702] loss: 45402.140625 rmse: 42300.00390625, kl_div: 3102.1357421875\n",
            "Epoch [2/50] Step [1340/1702] loss: 43870.625 rmse: 40732.796875, kl_div: 3137.82861328125\n",
            "Epoch [2/50] Step [1360/1702] loss: 44414.8046875 rmse: 41376.60546875, kl_div: 3038.19970703125\n",
            "Epoch [2/50] Step [1380/1702] loss: 42241.6328125 rmse: 39465.63671875, kl_div: 2775.994140625\n",
            "Epoch [2/50] Step [1400/1702] loss: 43112.19921875 rmse: 39716.984375, kl_div: 3395.214111328125\n",
            "Epoch [2/50] Step [1420/1702] loss: 42920.140625 rmse: 40055.609375, kl_div: 2864.530517578125\n",
            "Epoch [2/50] Step [1440/1702] loss: 41270.9765625 rmse: 39090.6484375, kl_div: 2180.330078125\n",
            "Epoch [2/50] Step [1460/1702] loss: 42636.703125 rmse: 40542.66015625, kl_div: 2094.04150390625\n",
            "Epoch [2/50] Step [1480/1702] loss: 41713.5 rmse: 39052.125, kl_div: 2661.374755859375\n",
            "Epoch [2/50] Step [1500/1702] loss: 44731.76953125 rmse: 42144.40625, kl_div: 2587.36474609375\n",
            "Epoch [2/50] Step [1520/1702] loss: 44861.15625 rmse: 42016.26953125, kl_div: 2844.8857421875\n",
            "Epoch [2/50] Step [1540/1702] loss: 41381.453125 rmse: 38849.890625, kl_div: 2531.5625\n",
            "Epoch [2/50] Step [1560/1702] loss: 44500.21875 rmse: 41765.5390625, kl_div: 2734.680908203125\n",
            "Epoch [2/50] Step [1580/1702] loss: 44594.0078125 rmse: 42006.80859375, kl_div: 2587.19873046875\n",
            "Epoch [2/50] Step [1600/1702] loss: 45598.68359375 rmse: 42382.9765625, kl_div: 3215.70703125\n",
            "Epoch [2/50] Step [1620/1702] loss: 42948.78515625 rmse: 39587.0703125, kl_div: 3361.714599609375\n",
            "Epoch [2/50] Step [1640/1702] loss: 43787.234375 rmse: 40589.80859375, kl_div: 3197.424072265625\n",
            "Epoch [2/50] Step [1660/1702] loss: 43664.2578125 rmse: 40926.2109375, kl_div: 2738.047607421875\n",
            "Epoch [2/50] Step [1680/1702] loss: 43663.67578125 rmse: 40780.265625, kl_div: 2883.41162109375\n",
            "Epoch [2/50] Step [1700/1702] loss: 44233.421875 rmse: 41288.375, kl_div: 2945.04638671875\n",
            "Epoch [3/50] Step [20/1702] loss: 42764.34375 rmse: 40577.69140625, kl_div: 2186.65185546875\n",
            "Epoch [3/50] Step [40/1702] loss: 43221.140625 rmse: 40573.7421875, kl_div: 2647.3984375\n",
            "Epoch [3/50] Step [60/1702] loss: 45072.33203125 rmse: 41595.9296875, kl_div: 3476.4013671875\n",
            "Epoch [3/50] Step [80/1702] loss: 43589.28125 rmse: 40155.1953125, kl_div: 3434.083984375\n",
            "Epoch [3/50] Step [100/1702] loss: 44025.78515625 rmse: 40693.921875, kl_div: 3331.863037109375\n",
            "Epoch [3/50] Step [120/1702] loss: 45295.77734375 rmse: 42379.8125, kl_div: 2915.96337890625\n",
            "Epoch [3/50] Step [140/1702] loss: 53171.0625 rmse: 44709.5234375, kl_div: 8461.5390625\n",
            "Epoch [3/50] Step [160/1702] loss: 47880.21484375 rmse: 42943.23828125, kl_div: 4936.97607421875\n",
            "Epoch [3/50] Step [180/1702] loss: 48872.8125 rmse: 43927.72265625, kl_div: 4945.08984375\n",
            "Epoch [3/50] Step [200/1702] loss: 48146.5703125 rmse: 43359.109375, kl_div: 4787.462890625\n",
            "Epoch [3/50] Step [220/1702] loss: 46457.33984375 rmse: 42464.7578125, kl_div: 3992.583740234375\n",
            "Epoch [3/50] Step [240/1702] loss: 48240.703125 rmse: 44743.38671875, kl_div: 3497.31494140625\n",
            "Epoch [3/50] Step [260/1702] loss: 43155.38671875 rmse: 39467.72265625, kl_div: 3687.66357421875\n",
            "Epoch [3/50] Step [280/1702] loss: 46279.3359375 rmse: 41981.359375, kl_div: 4297.9765625\n",
            "Epoch [3/50] Step [300/1702] loss: 48129.5234375 rmse: 44013.0625, kl_div: 4116.4619140625\n",
            "Epoch [3/50] Step [320/1702] loss: 44254.05078125 rmse: 40606.6953125, kl_div: 3647.35400390625\n",
            "Epoch [3/50] Step [340/1702] loss: 47074.0859375 rmse: 43157.45703125, kl_div: 3916.62744140625\n",
            "Epoch [3/50] Step [360/1702] loss: 45159.0390625 rmse: 41798.828125, kl_div: 3360.2109375\n",
            "Epoch [3/50] Step [380/1702] loss: 44774.37890625 rmse: 41636.84375, kl_div: 3137.5341796875\n",
            "Epoch [3/50] Step [400/1702] loss: 43672.35546875 rmse: 40411.8515625, kl_div: 3260.502197265625\n",
            "Epoch [3/50] Step [420/1702] loss: 44003.6953125 rmse: 40992.0859375, kl_div: 3011.607666015625\n",
            "Epoch [3/50] Step [440/1702] loss: 46351.328125 rmse: 43126.24609375, kl_div: 3225.08154296875\n",
            "Epoch [3/50] Step [460/1702] loss: 44329.38671875 rmse: 41524.3203125, kl_div: 2805.064697265625\n",
            "Epoch [3/50] Step [480/1702] loss: 45663.8984375 rmse: 42400.26171875, kl_div: 3263.63671875\n",
            "Epoch [3/50] Step [500/1702] loss: 45777.453125 rmse: 42980.546875, kl_div: 2796.90673828125\n",
            "Epoch [3/50] Step [520/1702] loss: 46440.03515625 rmse: 42366.359375, kl_div: 4073.674072265625\n",
            "Epoch [3/50] Step [540/1702] loss: 42965.734375 rmse: 39582.0859375, kl_div: 3383.650390625\n",
            "Epoch [3/50] Step [560/1702] loss: 43036.64453125 rmse: 40215.70703125, kl_div: 2820.9384765625\n",
            "Epoch [3/50] Step [580/1702] loss: 45043.0390625 rmse: 41701.5625, kl_div: 3341.4775390625\n",
            "Epoch [3/50] Step [600/1702] loss: 42328.09765625 rmse: 39865.5703125, kl_div: 2462.528564453125\n",
            "Epoch [3/50] Step [620/1702] loss: 42870.3046875 rmse: 40481.3046875, kl_div: 2389.00146484375\n",
            "Epoch [3/50] Step [640/1702] loss: 43641.68359375 rmse: 41176.42578125, kl_div: 2465.25732421875\n",
            "Epoch [3/50] Step [660/1702] loss: 44437.46875 rmse: 41560.4609375, kl_div: 2877.0087890625\n",
            "Epoch [3/50] Step [680/1702] loss: 42101.91796875 rmse: 39714.62890625, kl_div: 2387.28857421875\n",
            "Epoch [3/50] Step [700/1702] loss: 44922.3671875 rmse: 41756.4921875, kl_div: 3165.873779296875\n",
            "Epoch [3/50] Step [720/1702] loss: 43945.65625 rmse: 41375.953125, kl_div: 2569.7021484375\n",
            "Epoch [3/50] Step [740/1702] loss: 41703.8203125 rmse: 39183.21875, kl_div: 2520.60009765625\n",
            "Epoch [3/50] Step [760/1702] loss: 43454.26171875 rmse: 41294.140625, kl_div: 2160.1201171875\n",
            "Epoch [3/50] Step [780/1702] loss: 44935.96484375 rmse: 42438.3203125, kl_div: 2497.64404296875\n",
            "Epoch [3/50] Step [800/1702] loss: 42026.828125 rmse: 39647.171875, kl_div: 2379.654296875\n",
            "Epoch [3/50] Step [820/1702] loss: 44824.69140625 rmse: 42195.7109375, kl_div: 2628.98095703125\n",
            "Epoch [3/50] Step [840/1702] loss: 44672.3984375 rmse: 41933.93359375, kl_div: 2738.463623046875\n",
            "Epoch [3/50] Step [860/1702] loss: 44680.796875 rmse: 41725.51953125, kl_div: 2955.27880859375\n",
            "Epoch [3/50] Step [880/1702] loss: 43139.015625 rmse: 40697.74609375, kl_div: 2441.27099609375\n",
            "Epoch [3/50] Step [900/1702] loss: 42912.99609375 rmse: 40478.79296875, kl_div: 2434.20458984375\n",
            "Epoch [3/50] Step [920/1702] loss: 42604.24609375 rmse: 40328.78125, kl_div: 2275.46533203125\n",
            "Epoch [3/50] Step [940/1702] loss: 43133.39453125 rmse: 39980.03125, kl_div: 3153.361572265625\n",
            "Epoch [3/50] Step [960/1702] loss: 47149.69921875 rmse: 42895.5546875, kl_div: 4254.1435546875\n",
            "Epoch [3/50] Step [980/1702] loss: 43644.9609375 rmse: 41478.609375, kl_div: 2166.349609375\n",
            "Epoch [3/50] Step [1000/1702] loss: 42017.79296875 rmse: 39588.25390625, kl_div: 2429.537841796875\n",
            "Epoch [3/50] Step [1020/1702] loss: 46189.4296875 rmse: 43684.609375, kl_div: 2504.81982421875\n",
            "Epoch [3/50] Step [1040/1702] loss: 42874.63671875 rmse: 40614.8203125, kl_div: 2259.81787109375\n",
            "Epoch [3/50] Step [1060/1702] loss: 41250.015625 rmse: 38760.4140625, kl_div: 2489.60107421875\n",
            "Epoch [3/50] Step [1080/1702] loss: 46895.1328125 rmse: 41953.0390625, kl_div: 4942.0927734375\n",
            "Epoch [3/50] Step [1100/1702] loss: 44135.1328125 rmse: 39864.2265625, kl_div: 4270.90625\n",
            "Epoch [3/50] Step [1120/1702] loss: 46443.265625 rmse: 41389.87109375, kl_div: 5053.396484375\n",
            "Epoch [3/50] Step [1140/1702] loss: 42125.77734375 rmse: 38631.11328125, kl_div: 3494.6650390625\n",
            "Epoch [3/50] Step [1160/1702] loss: 45130.05859375 rmse: 41393.44921875, kl_div: 3736.6083984375\n",
            "Epoch [3/50] Step [1180/1702] loss: 42587.875 rmse: 39422.2109375, kl_div: 3165.66552734375\n",
            "Epoch [3/50] Step [1200/1702] loss: 47204.35546875 rmse: 43109.0390625, kl_div: 4095.3173828125\n",
            "Epoch [3/50] Step [1220/1702] loss: 45585.76171875 rmse: 41980.26171875, kl_div: 3605.499267578125\n",
            "Epoch [3/50] Step [1240/1702] loss: 44978.31640625 rmse: 41292.1796875, kl_div: 3686.1357421875\n",
            "Epoch [3/50] Step [1260/1702] loss: 43715.9765625 rmse: 40574.3828125, kl_div: 3141.59375\n",
            "Epoch [3/50] Step [1280/1702] loss: 44032.37109375 rmse: 40528.23046875, kl_div: 3504.1416015625\n",
            "Epoch [3/50] Step [1300/1702] loss: 43887.046875 rmse: 40449.94921875, kl_div: 3437.0986328125\n",
            "Epoch [3/50] Step [1320/1702] loss: 47112.8515625 rmse: 43808.515625, kl_div: 3304.3369140625\n",
            "Epoch [3/50] Step [1340/1702] loss: 45552.87109375 rmse: 42306.09765625, kl_div: 3246.7734375\n",
            "Epoch [3/50] Step [1360/1702] loss: 45078.03515625 rmse: 42133.4921875, kl_div: 2944.54150390625\n",
            "Epoch [3/50] Step [1380/1702] loss: 42660.91015625 rmse: 39724.26171875, kl_div: 2936.64794921875\n",
            "Epoch [3/50] Step [1400/1702] loss: 46035.234375 rmse: 42785.46484375, kl_div: 3249.77099609375\n",
            "Epoch [3/50] Step [1420/1702] loss: 42989.5546875 rmse: 40008.3125, kl_div: 2981.24169921875\n",
            "Epoch [3/50] Step [1440/1702] loss: 46429.03125 rmse: 41720.1796875, kl_div: 4708.85205078125\n",
            "Epoch [3/50] Step [1460/1702] loss: 46841.5234375 rmse: 43383.8984375, kl_div: 3457.62548828125\n",
            "Epoch [3/50] Step [1480/1702] loss: 42619.65625 rmse: 38582.421875, kl_div: 4037.23291015625\n",
            "Epoch [3/50] Step [1500/1702] loss: 73845.171875 rmse: 43213.59375, kl_div: 30631.58203125\n",
            "Epoch [3/50] Step [1520/1702] loss: 42045.80078125 rmse: 39035.0234375, kl_div: 3010.77783203125\n",
            "Epoch [3/50] Step [1540/1702] loss: 43148.6640625 rmse: 40162.66796875, kl_div: 2985.997314453125\n",
            "Epoch [3/50] Step [1560/1702] loss: 42153.43359375 rmse: 39299.67578125, kl_div: 2853.7568359375\n",
            "Epoch [3/50] Step [1580/1702] loss: 42008.5078125 rmse: 39233.9296875, kl_div: 2774.579345703125\n",
            "Epoch [3/50] Step [1600/1702] loss: 44930.6328125 rmse: 41437.4453125, kl_div: 3493.188232421875\n",
            "Epoch [3/50] Step [1620/1702] loss: 45724.828125 rmse: 42099.2578125, kl_div: 3625.572265625\n",
            "Epoch [3/50] Step [1640/1702] loss: 44642.98828125 rmse: 41629.5625, kl_div: 3013.42578125\n",
            "Epoch [3/50] Step [1660/1702] loss: 44084.92578125 rmse: 40617.43359375, kl_div: 3467.492431640625\n",
            "Epoch [3/50] Step [1680/1702] loss: 43446.70703125 rmse: 40462.3515625, kl_div: 2984.354248046875\n",
            "Epoch [3/50] Step [1700/1702] loss: 43412.6953125 rmse: 40462.6796875, kl_div: 2950.01513671875\n",
            "Epoch [4/50] Step [20/1702] loss: 44273.30078125 rmse: 41109.546875, kl_div: 3163.75341796875\n",
            "Epoch [4/50] Step [40/1702] loss: 50204.56640625 rmse: 44698.8359375, kl_div: 5505.7294921875\n",
            "Epoch [4/50] Step [60/1702] loss: 45922.59765625 rmse: 42942.7265625, kl_div: 2979.872314453125\n",
            "Epoch [4/50] Step [80/1702] loss: 45822.1875 rmse: 42676.76953125, kl_div: 3145.4189453125\n",
            "Epoch [4/50] Step [100/1702] loss: 45837.3671875 rmse: 42436.97265625, kl_div: 3400.396484375\n",
            "Epoch [4/50] Step [120/1702] loss: 46646.4453125 rmse: 42988.87109375, kl_div: 3657.57373046875\n",
            "Epoch [4/50] Step [140/1702] loss: 43814.46875 rmse: 40903.07421875, kl_div: 2911.39501953125\n",
            "Epoch [4/50] Step [160/1702] loss: 44042.5234375 rmse: 40856.6640625, kl_div: 3185.8603515625\n",
            "Epoch [4/50] Step [180/1702] loss: 47602.80859375 rmse: 42657.25, kl_div: 4945.5576171875\n",
            "Epoch [4/50] Step [200/1702] loss: 49778.1875 rmse: 44888.1640625, kl_div: 4890.0234375\n",
            "Epoch [4/50] Step [220/1702] loss: 46213.828125 rmse: 41922.296875, kl_div: 4291.529296875\n",
            "Epoch [4/50] Step [240/1702] loss: 46236.171875 rmse: 41784.3046875, kl_div: 4451.869140625\n",
            "Epoch [4/50] Step [260/1702] loss: 45861.11328125 rmse: 41882.48046875, kl_div: 3978.6318359375\n",
            "Epoch [4/50] Step [280/1702] loss: 43465.0078125 rmse: 39412.8359375, kl_div: 4052.170654296875\n",
            "Epoch [4/50] Step [300/1702] loss: 47013.58984375 rmse: 42453.3984375, kl_div: 4560.19287109375\n",
            "Epoch [4/50] Step [320/1702] loss: 46315.9765625 rmse: 42160.46875, kl_div: 4155.5087890625\n",
            "Epoch [4/50] Step [340/1702] loss: 43420.58984375 rmse: 39592.796875, kl_div: 3827.79296875\n",
            "Epoch [4/50] Step [360/1702] loss: 44673.3125 rmse: 40738.171875, kl_div: 3935.14111328125\n",
            "Epoch [4/50] Step [380/1702] loss: 45054.375 rmse: 41507.84765625, kl_div: 3546.52880859375\n",
            "Epoch [4/50] Step [400/1702] loss: 44615.58203125 rmse: 41103.359375, kl_div: 3512.223876953125\n",
            "Epoch [4/50] Step [420/1702] loss: 96611328.0 rmse: 50089.984375, kl_div: 96561240.0\n",
            "Epoch [4/50] Step [440/1702] loss: 46295.484375 rmse: 40978.1796875, kl_div: 5317.30419921875\n",
            "Epoch [4/50] Step [460/1702] loss: 45817.04296875 rmse: 40545.3828125, kl_div: 5271.65966796875\n",
            "Epoch [4/50] Step [480/1702] loss: 47255.66015625 rmse: 42526.26953125, kl_div: 4729.3896484375\n",
            "Epoch [4/50] Step [500/1702] loss: 46563.7109375 rmse: 41010.59375, kl_div: 5553.11865234375\n",
            "Epoch [4/50] Step [520/1702] loss: 47087.8359375 rmse: 42496.31640625, kl_div: 4591.52001953125\n",
            "Epoch [4/50] Step [540/1702] loss: 44157.33203125 rmse: 39517.40625, kl_div: 4639.92626953125\n",
            "Epoch [4/50] Step [560/1702] loss: 44561.8046875 rmse: 39681.8984375, kl_div: 4879.90478515625\n",
            "Epoch [4/50] Step [580/1702] loss: 44595.1796875 rmse: 40101.47265625, kl_div: 4493.70849609375\n",
            "Epoch [4/50] Step [600/1702] loss: 45405.5859375 rmse: 40926.765625, kl_div: 4478.82177734375\n",
            "Epoch [4/50] Step [620/1702] loss: 44043.85546875 rmse: 39747.87890625, kl_div: 4295.9755859375\n",
            "Epoch [4/50] Step [640/1702] loss: 58216.80859375 rmse: 46285.4375, kl_div: 11931.3701171875\n",
            "Epoch [4/50] Step [660/1702] loss: 48137.421875 rmse: 43580.0, kl_div: 4557.421875\n",
            "Epoch [4/50] Step [680/1702] loss: 46832.61328125 rmse: 42180.3984375, kl_div: 4652.21337890625\n",
            "Epoch [4/50] Step [700/1702] loss: 45290.34375 rmse: 40872.81640625, kl_div: 4417.52783203125\n",
            "Epoch [4/50] Step [720/1702] loss: 42136.37890625 rmse: 37430.0390625, kl_div: 4706.33935546875\n",
            "Epoch [4/50] Step [740/1702] loss: 47203.57421875 rmse: 42397.0625, kl_div: 4806.5126953125\n",
            "Epoch [4/50] Step [760/1702] loss: 46240.49609375 rmse: 41763.1328125, kl_div: 4477.3642578125\n",
            "Epoch [4/50] Step [780/1702] loss: 44608.4609375 rmse: 40320.953125, kl_div: 4287.50927734375\n",
            "Epoch [4/50] Step [800/1702] loss: 46764.3671875 rmse: 41225.57421875, kl_div: 5538.7939453125\n",
            "Epoch [4/50] Step [820/1702] loss: 45866.109375 rmse: 40835.734375, kl_div: 5030.37451171875\n",
            "Epoch [4/50] Step [840/1702] loss: 47031.02734375 rmse: 41565.3359375, kl_div: 5465.68994140625\n",
            "Epoch [4/50] Step [860/1702] loss: 47046.9453125 rmse: 41909.8828125, kl_div: 5137.06396484375\n",
            "Epoch [4/50] Step [880/1702] loss: 47226.90234375 rmse: 42041.5625, kl_div: 5185.34033203125\n",
            "Epoch [4/50] Step [900/1702] loss: 46506.3671875 rmse: 41236.7578125, kl_div: 5269.611328125\n",
            "Epoch [4/50] Step [920/1702] loss: 44274.1171875 rmse: 39655.1953125, kl_div: 4618.92236328125\n",
            "Epoch [4/50] Step [940/1702] loss: 45311.22265625 rmse: 40532.33984375, kl_div: 4778.8837890625\n",
            "Epoch [4/50] Step [960/1702] loss: 45255.49609375 rmse: 40417.86328125, kl_div: 4837.63330078125\n",
            "Epoch [4/50] Step [980/1702] loss: 46689.6171875 rmse: 42241.3515625, kl_div: 4448.26416015625\n",
            "Epoch [4/50] Step [1000/1702] loss: 46218.53515625 rmse: 41533.0703125, kl_div: 4685.46484375\n",
            "Epoch [4/50] Step [1020/1702] loss: 46009.24609375 rmse: 41407.0703125, kl_div: 4602.17626953125\n",
            "Epoch [4/50] Step [1040/1702] loss: 47146.55078125 rmse: 43205.58203125, kl_div: 3940.969482421875\n",
            "Epoch [4/50] Step [1060/1702] loss: 44536.09765625 rmse: 40389.21484375, kl_div: 4146.8837890625\n",
            "Epoch [4/50] Step [1080/1702] loss: 45914.48828125 rmse: 41502.68359375, kl_div: 4411.80419921875\n",
            "Epoch [4/50] Step [1100/1702] loss: 42782.28125 rmse: 38372.29296875, kl_div: 4409.98828125\n",
            "Epoch [4/50] Step [1120/1702] loss: 44616.265625 rmse: 40935.8515625, kl_div: 3680.4150390625\n",
            "Epoch [4/50] Step [1140/1702] loss: 46151.79296875 rmse: 42026.90234375, kl_div: 4124.89208984375\n",
            "Epoch [4/50] Step [1160/1702] loss: 44383.9375 rmse: 40406.21484375, kl_div: 3977.724365234375\n",
            "Epoch [4/50] Step [1180/1702] loss: 43683.765625 rmse: 39328.21875, kl_div: 4355.546875\n",
            "Epoch [4/50] Step [1200/1702] loss: 45091.49609375 rmse: 41007.69921875, kl_div: 4083.795166015625\n",
            "Epoch [4/50] Step [1220/1702] loss: 50016.80859375 rmse: 44285.48046875, kl_div: 5731.3271484375\n",
            "Epoch [4/50] Step [1240/1702] loss: 48329.49609375 rmse: 42654.8359375, kl_div: 5674.6591796875\n",
            "Epoch [4/50] Step [1260/1702] loss: 51790.5078125 rmse: 38765.125, kl_div: 13025.3818359375\n",
            "Epoch [4/50] Step [1280/1702] loss: 46257.19140625 rmse: 40947.27734375, kl_div: 5309.91259765625\n",
            "Epoch [4/50] Step [1300/1702] loss: 46849.65234375 rmse: 41502.234375, kl_div: 5347.4189453125\n",
            "Epoch [4/50] Step [1320/1702] loss: 47701.0546875 rmse: 41953.59375, kl_div: 5747.46044921875\n",
            "Epoch [4/50] Step [1340/1702] loss: 48364.359375 rmse: 42708.1640625, kl_div: 5656.197265625\n",
            "Epoch [4/50] Step [1360/1702] loss: 46318.26953125 rmse: 41020.30078125, kl_div: 5297.96728515625\n",
            "Epoch [4/50] Step [1380/1702] loss: 46104.9921875 rmse: 40898.78125, kl_div: 5206.2119140625\n",
            "Epoch [4/50] Step [1400/1702] loss: 45677.44921875 rmse: 40152.890625, kl_div: 5524.5595703125\n",
            "Epoch [4/50] Step [1420/1702] loss: 45812.7890625 rmse: 40513.46484375, kl_div: 5299.32275390625\n",
            "Epoch [4/50] Step [1440/1702] loss: 43939.05859375 rmse: 38831.43359375, kl_div: 5107.62548828125\n",
            "Epoch [4/50] Step [1460/1702] loss: 49959.4921875 rmse: 44161.37890625, kl_div: 5798.11279296875\n",
            "Epoch [4/50] Step [1480/1702] loss: 42842.6484375 rmse: 38217.875, kl_div: 4624.77392578125\n",
            "Epoch [4/50] Step [1500/1702] loss: 49082.9375 rmse: 43473.0625, kl_div: 5609.87646484375\n",
            "Epoch [4/50] Step [1520/1702] loss: 45683.1171875 rmse: 39915.73828125, kl_div: 5767.37744140625\n",
            "Epoch [4/50] Step [1540/1702] loss: 48281.70703125 rmse: 42530.3828125, kl_div: 5751.3251953125\n",
            "Epoch [4/50] Step [1560/1702] loss: 52748.71875 rmse: 45462.203125, kl_div: 7286.517578125\n",
            "Epoch [4/50] Step [1580/1702] loss: 53012.734375 rmse: 43138.0546875, kl_div: 9874.677734375\n",
            "Epoch [4/50] Step [1600/1702] loss: 50663.4921875 rmse: 41786.48828125, kl_div: 8877.00390625\n",
            "Epoch [4/50] Step [1620/1702] loss: 49983.59375 rmse: 41118.2265625, kl_div: 8865.365234375\n",
            "Epoch [4/50] Step [1640/1702] loss: 49311.3671875 rmse: 39766.046875, kl_div: 9545.318359375\n",
            "Epoch [4/50] Step [1660/1702] loss: 52712.265625 rmse: 43871.9140625, kl_div: 8840.353515625\n",
            "Epoch [4/50] Step [1680/1702] loss: 49863.62890625 rmse: 40745.328125, kl_div: 9118.30078125\n",
            "Epoch [4/50] Step [1700/1702] loss: 53013.5546875 rmse: 44157.60546875, kl_div: 8855.94921875\n",
            "Epoch [5/50] Step [20/1702] loss: 50664.48046875 rmse: 42491.46875, kl_div: 8173.0126953125\n",
            "Epoch [5/50] Step [40/1702] loss: 49615.4140625 rmse: 40922.140625, kl_div: 8693.2744140625\n",
            "Epoch [5/50] Step [60/1702] loss: 48305.796875 rmse: 39716.0078125, kl_div: 8589.7900390625\n",
            "Epoch [5/50] Step [80/1702] loss: 49444.8125 rmse: 41330.453125, kl_div: 8114.3603515625\n",
            "Epoch [5/50] Step [100/1702] loss: 49623.85546875 rmse: 41517.33984375, kl_div: 8106.51708984375\n",
            "Epoch [5/50] Step [120/1702] loss: 50284.703125 rmse: 42719.015625, kl_div: 7565.685546875\n",
            "Epoch [5/50] Step [140/1702] loss: 49558.484375 rmse: 41885.2890625, kl_div: 7673.19482421875\n",
            "Epoch [5/50] Step [160/1702] loss: 49509.54296875 rmse: 42010.96875, kl_div: 7498.57470703125\n",
            "Epoch [5/50] Step [180/1702] loss: 48964.9296875 rmse: 40736.6015625, kl_div: 8228.3291015625\n",
            "Epoch [5/50] Step [200/1702] loss: 46608.03125 rmse: 39065.5234375, kl_div: 7542.5068359375\n",
            "Epoch [5/50] Step [220/1702] loss: 48445.23046875 rmse: 40903.96875, kl_div: 7541.2607421875\n",
            "Epoch [5/50] Step [240/1702] loss: 48351.625 rmse: 40700.3046875, kl_div: 7651.3203125\n",
            "Epoch [5/50] Step [260/1702] loss: 47763.73828125 rmse: 40083.59765625, kl_div: 7680.140625\n",
            "Epoch [5/50] Step [280/1702] loss: 47859.9921875 rmse: 39122.5234375, kl_div: 8737.466796875\n",
            "Epoch [5/50] Step [300/1702] loss: 46914.3359375 rmse: 39166.0390625, kl_div: 7748.29541015625\n",
            "Epoch [5/50] Step [320/1702] loss: 50277.61328125 rmse: 42395.7421875, kl_div: 7881.87109375\n",
            "Epoch [5/50] Step [340/1702] loss: 48652.11328125 rmse: 41403.5703125, kl_div: 7248.54296875\n",
            "Epoch [5/50] Step [360/1702] loss: 51590.5859375 rmse: 43342.78125, kl_div: 8247.8037109375\n",
            "Epoch [5/50] Step [380/1702] loss: 51720.23046875 rmse: 43494.49609375, kl_div: 8225.734375\n",
            "Epoch [5/50] Step [400/1702] loss: 50103.078125 rmse: 42180.2890625, kl_div: 7922.791015625\n",
            "Epoch [5/50] Step [420/1702] loss: 48229.2109375 rmse: 40919.125, kl_div: 7310.08447265625\n",
            "Epoch [5/50] Step [440/1702] loss: 49927.80078125 rmse: 42443.90625, kl_div: 7483.89501953125\n",
            "Epoch [5/50] Step [460/1702] loss: 48552.2890625 rmse: 41177.21875, kl_div: 7375.07177734375\n",
            "Epoch [5/50] Step [480/1702] loss: 48994.66796875 rmse: 41775.2109375, kl_div: 7219.45751953125\n",
            "Epoch [5/50] Step [500/1702] loss: 48550.609375 rmse: 41530.95703125, kl_div: 7019.65234375\n",
            "Epoch [5/50] Step [520/1702] loss: 45764.29296875 rmse: 38888.7109375, kl_div: 6875.5810546875\n",
            "Epoch [5/50] Step [540/1702] loss: 50083.8359375 rmse: 42738.8515625, kl_div: 7344.9833984375\n",
            "Epoch [5/50] Step [560/1702] loss: 49908.125 rmse: 42921.828125, kl_div: 6986.2958984375\n",
            "Epoch [5/50] Step [580/1702] loss: 45365.1171875 rmse: 38843.640625, kl_div: 6521.47705078125\n",
            "Epoch [5/50] Step [600/1702] loss: 45792.5234375 rmse: 39021.796875, kl_div: 6770.724609375\n",
            "Epoch [5/50] Step [620/1702] loss: 47632.9609375 rmse: 40696.83984375, kl_div: 6936.12060546875\n",
            "Epoch [5/50] Step [640/1702] loss: 47030.12109375 rmse: 40241.578125, kl_div: 6788.54345703125\n",
            "Epoch [5/50] Step [660/1702] loss: 47282.74609375 rmse: 40480.390625, kl_div: 6802.35595703125\n",
            "Epoch [5/50] Step [680/1702] loss: 49379.44140625 rmse: 42239.0234375, kl_div: 7140.41650390625\n",
            "Epoch [5/50] Step [700/1702] loss: 48751.40234375 rmse: 41634.4609375, kl_div: 7116.94140625\n",
            "Epoch [5/50] Step [720/1702] loss: 48381.8984375 rmse: 42012.125, kl_div: 6369.775390625\n",
            "Epoch [5/50] Step [740/1702] loss: 47469.390625 rmse: 40796.109375, kl_div: 6673.279296875\n",
            "Epoch [5/50] Step [760/1702] loss: 48058.9375 rmse: 42021.05078125, kl_div: 6037.88525390625\n",
            "Epoch [5/50] Step [780/1702] loss: 46492.62109375 rmse: 40487.1796875, kl_div: 6005.4404296875\n",
            "Epoch [5/50] Step [800/1702] loss: 48373.65625 rmse: 42569.0, kl_div: 5804.6572265625\n",
            "Epoch [5/50] Step [820/1702] loss: 48759.8984375 rmse: 42835.703125, kl_div: 5924.1953125\n",
            "Epoch [5/50] Step [840/1702] loss: 43504.7890625 rmse: 37630.75390625, kl_div: 5874.033203125\n",
            "Epoch [5/50] Step [860/1702] loss: 47120.3984375 rmse: 41308.71484375, kl_div: 5811.6845703125\n",
            "Epoch [5/50] Step [880/1702] loss: 51135.75390625 rmse: 45146.84375, kl_div: 5988.91015625\n",
            "Epoch [5/50] Step [900/1702] loss: 44039.1328125 rmse: 38115.86328125, kl_div: 5923.267578125\n",
            "Epoch [5/50] Step [920/1702] loss: 47583.6953125 rmse: 41162.92578125, kl_div: 6420.76904296875\n",
            "Epoch [5/50] Step [940/1702] loss: 47681.8984375 rmse: 41504.8828125, kl_div: 6177.015625\n",
            "Epoch [5/50] Step [960/1702] loss: 45414.90625 rmse: 39783.1015625, kl_div: 5631.806640625\n",
            "Epoch [5/50] Step [980/1702] loss: 43267.57421875 rmse: 37420.296875, kl_div: 5847.27880859375\n",
            "Epoch [5/50] Step [1000/1702] loss: 47444.75 rmse: 41709.98046875, kl_div: 5734.7705078125\n",
            "Epoch [5/50] Step [1020/1702] loss: 46392.84375 rmse: 40379.203125, kl_div: 6013.64111328125\n",
            "Epoch [5/50] Step [1040/1702] loss: 45296.12109375 rmse: 39670.4921875, kl_div: 5625.63037109375\n",
            "Epoch [5/50] Step [1060/1702] loss: 45999.7421875 rmse: 40412.58984375, kl_div: 5587.15380859375\n",
            "Epoch [5/50] Step [1080/1702] loss: 47089.09375 rmse: 40655.0703125, kl_div: 6434.0244140625\n",
            "Epoch [5/50] Step [1100/1702] loss: 45748.6328125 rmse: 40058.59375, kl_div: 5690.041015625\n",
            "Epoch [5/50] Step [1120/1702] loss: 45198.7265625 rmse: 39305.0546875, kl_div: 5893.67236328125\n",
            "Epoch [5/50] Step [1140/1702] loss: 47230.3125 rmse: 40966.3828125, kl_div: 6263.9306640625\n",
            "Epoch [5/50] Step [1160/1702] loss: 304031424.0 rmse: 50496.4375, kl_div: 303980928.0\n",
            "Epoch [5/50] Step [1180/1702] loss: 46117.58984375 rmse: 39261.2109375, kl_div: 6856.37939453125\n",
            "Epoch [5/50] Step [1200/1702] loss: 13890944.0 rmse: 47435.05859375, kl_div: 13843509.0\n",
            "Epoch [5/50] Step [1220/1702] loss: 46417.3671875 rmse: 39385.0, kl_div: 7032.3662109375\n",
            "Epoch [5/50] Step [1240/1702] loss: 48625.90625 rmse: 41315.4375, kl_div: 7310.46875\n",
            "Epoch [5/50] Step [1260/1702] loss: 46384.203125 rmse: 39556.03515625, kl_div: 6828.16943359375\n",
            "Epoch [5/50] Step [1280/1702] loss: 46948.484375 rmse: 40043.140625, kl_div: 6905.3427734375\n",
            "Epoch [5/50] Step [1300/1702] loss: 49616.32421875 rmse: 42471.015625, kl_div: 7145.3095703125\n",
            "Epoch [5/50] Step [1320/1702] loss: 47316.09765625 rmse: 41355.2421875, kl_div: 5960.85498046875\n",
            "Epoch [5/50] Step [1340/1702] loss: 47542.27734375 rmse: 41241.6875, kl_div: 6300.5888671875\n",
            "Epoch [5/50] Step [1360/1702] loss: 46776.53125 rmse: 38802.6484375, kl_div: 7973.884765625\n",
            "Epoch [5/50] Step [1380/1702] loss: 46882.27734375 rmse: 39761.2578125, kl_div: 7121.02001953125\n",
            "Epoch [5/50] Step [1400/1702] loss: 50369.4921875 rmse: 43236.66015625, kl_div: 7132.83203125\n",
            "Epoch [5/50] Step [1420/1702] loss: 47468.33203125 rmse: 40746.6171875, kl_div: 6721.71630859375\n",
            "Epoch [5/50] Step [1440/1702] loss: 45541.7421875 rmse: 38932.43359375, kl_div: 6609.306640625\n",
            "Epoch [5/50] Step [1460/1702] loss: 49904.20703125 rmse: 43116.3046875, kl_div: 6787.9013671875\n",
            "Epoch [5/50] Step [1480/1702] loss: 115855.921875 rmse: 45227.8046875, kl_div: 70628.1171875\n",
            "Epoch [5/50] Step [1500/1702] loss: 44822.9296875 rmse: 38759.5078125, kl_div: 6063.421875\n",
            "Epoch [5/50] Step [1520/1702] loss: 49180.9921875 rmse: 42045.703125, kl_div: 7135.28759765625\n",
            "Epoch [5/50] Step [1540/1702] loss: 48167.6875 rmse: 41132.3984375, kl_div: 7035.287109375\n",
            "Epoch [5/50] Step [1560/1702] loss: 49515.93359375 rmse: 42330.328125, kl_div: 7185.6064453125\n",
            "Epoch [5/50] Step [1580/1702] loss: 49019.16796875 rmse: 41467.25, kl_div: 7551.9189453125\n",
            "Epoch [5/50] Step [1600/1702] loss: 47696.59375 rmse: 40309.859375, kl_div: 7386.732421875\n",
            "Epoch [5/50] Step [1620/1702] loss: 52951.3359375 rmse: 42532.5234375, kl_div: 10418.8134765625\n",
            "Epoch [5/50] Step [1640/1702] loss: 51436.66015625 rmse: 44171.4765625, kl_div: 7265.1845703125\n",
            "Epoch [5/50] Step [1660/1702] loss: 49575.546875 rmse: 41884.125, kl_div: 7691.42333984375\n",
            "Epoch [5/50] Step [1680/1702] loss: 48946.34765625 rmse: 41717.5390625, kl_div: 7228.80908203125\n",
            "Epoch [5/50] Step [1700/1702] loss: 45803.80078125 rmse: 39767.7734375, kl_div: 6036.0283203125\n",
            "Epoch [6/50] Step [20/1702] loss: 47444.4296875 rmse: 39757.75, kl_div: 7686.67822265625\n",
            "Epoch [6/50] Step [40/1702] loss: 49155.65625 rmse: 40861.22265625, kl_div: 8294.4345703125\n",
            "Epoch [6/50] Step [60/1702] loss: 51140.6171875 rmse: 43364.94921875, kl_div: 7775.66943359375\n",
            "Epoch [6/50] Step [80/1702] loss: 47151.125 rmse: 39075.671875, kl_div: 8075.451171875\n",
            "Epoch [6/50] Step [100/1702] loss: 47892.5 rmse: 39886.8828125, kl_div: 8005.61669921875\n",
            "Epoch [6/50] Step [120/1702] loss: 49154.08984375 rmse: 41277.98046875, kl_div: 7876.11083984375\n",
            "Epoch [6/50] Step [140/1702] loss: 50716.53125 rmse: 42763.328125, kl_div: 7953.2021484375\n",
            "Epoch [6/50] Step [160/1702] loss: 49137.78125 rmse: 41249.19921875, kl_div: 7888.58349609375\n",
            "Epoch [6/50] Step [180/1702] loss: 44213.01171875 rmse: 38179.8828125, kl_div: 6033.12939453125\n",
            "Epoch [6/50] Step [200/1702] loss: 44557.46484375 rmse: 37148.8125, kl_div: 7408.6533203125\n",
            "Epoch [6/50] Step [220/1702] loss: 47177.7890625 rmse: 39859.73828125, kl_div: 7318.0498046875\n",
            "Epoch [6/50] Step [240/1702] loss: 48657.37109375 rmse: 41699.65625, kl_div: 6957.7158203125\n",
            "Epoch [6/50] Step [260/1702] loss: 48568.24609375 rmse: 40705.96875, kl_div: 7862.27783203125\n",
            "Epoch [6/50] Step [280/1702] loss: 50447.84375 rmse: 41172.71484375, kl_div: 9275.12890625\n",
            "Epoch [6/50] Step [300/1702] loss: 49734.3125 rmse: 40457.2421875, kl_div: 9277.072265625\n",
            "Epoch [6/50] Step [320/1702] loss: 47084.640625 rmse: 39023.7578125, kl_div: 8060.8837890625\n",
            "Epoch [6/50] Step [340/1702] loss: 49730.9453125 rmse: 41485.12109375, kl_div: 8245.826171875\n",
            "Epoch [6/50] Step [360/1702] loss: 50552.4921875 rmse: 41756.6484375, kl_div: 8795.845703125\n",
            "Epoch [6/50] Step [380/1702] loss: 48609.921875 rmse: 40075.4375, kl_div: 8534.484375\n",
            "Epoch [6/50] Step [400/1702] loss: 51614.0390625 rmse: 42880.7265625, kl_div: 8733.310546875\n",
            "Epoch [6/50] Step [420/1702] loss: 48936.0390625 rmse: 40911.77734375, kl_div: 8024.26123046875\n",
            "Epoch [6/50] Step [440/1702] loss: 49971.375 rmse: 42038.65234375, kl_div: 7932.72265625\n",
            "Epoch [6/50] Step [460/1702] loss: 48385.1484375 rmse: 40747.8515625, kl_div: 7637.294921875\n",
            "Epoch [6/50] Step [480/1702] loss: 46846.73046875 rmse: 38461.828125, kl_div: 8384.90234375\n",
            "Epoch [6/50] Step [500/1702] loss: 48850.94921875 rmse: 40368.3125, kl_div: 8482.6376953125\n",
            "Epoch [6/50] Step [520/1702] loss: 49543.83984375 rmse: 41291.42578125, kl_div: 8252.4140625\n",
            "Epoch [6/50] Step [540/1702] loss: 48892.8125 rmse: 41403.578125, kl_div: 7489.234375\n",
            "Epoch [6/50] Step [560/1702] loss: 51113.72265625 rmse: 42524.37109375, kl_div: 8589.3515625\n",
            "Epoch [6/50] Step [580/1702] loss: 51800.703125 rmse: 42448.9453125, kl_div: 9351.7578125\n",
            "Epoch [6/50] Step [600/1702] loss: 50172.11328125 rmse: 41150.2109375, kl_div: 9021.90234375\n",
            "Epoch [6/50] Step [620/1702] loss: 45368.421875 rmse: 38070.41796875, kl_div: 7298.0029296875\n",
            "Epoch [6/50] Step [640/1702] loss: 50468.5625 rmse: 42756.76953125, kl_div: 7711.79150390625\n",
            "Epoch [6/50] Step [660/1702] loss: 49921.83203125 rmse: 41166.4140625, kl_div: 8755.4169921875\n",
            "Epoch [6/50] Step [680/1702] loss: 50712.48046875 rmse: 42119.7578125, kl_div: 8592.7236328125\n",
            "Epoch [6/50] Step [700/1702] loss: 49477.546875 rmse: 41529.90234375, kl_div: 7947.6455078125\n",
            "Epoch [6/50] Step [720/1702] loss: 46407.0390625 rmse: 38043.6640625, kl_div: 8363.376953125\n",
            "Epoch [6/50] Step [740/1702] loss: 49674.203125 rmse: 41524.671875, kl_div: 8149.533203125\n",
            "Epoch [6/50] Step [760/1702] loss: 50250.96484375 rmse: 41042.83984375, kl_div: 9208.125\n",
            "Epoch [6/50] Step [780/1702] loss: 47817.8671875 rmse: 38860.19140625, kl_div: 8957.6748046875\n",
            "Epoch [6/50] Step [800/1702] loss: 50417.6875 rmse: 42872.515625, kl_div: 7545.171875\n",
            "Epoch [6/50] Step [820/1702] loss: 51195.7421875 rmse: 42154.296875, kl_div: 9041.443359375\n",
            "Epoch [6/50] Step [840/1702] loss: 53571.8828125 rmse: 41360.15625, kl_div: 12211.728515625\n",
            "Epoch [6/50] Step [860/1702] loss: 54098.87109375 rmse: 42264.0234375, kl_div: 11834.84765625\n",
            "Epoch [6/50] Step [880/1702] loss: 50267.0546875 rmse: 39519.75, kl_div: 10747.3046875\n",
            "Epoch [6/50] Step [900/1702] loss: 48726.640625 rmse: 37997.6640625, kl_div: 10728.9755859375\n",
            "Epoch [6/50] Step [920/1702] loss: 52388.3515625 rmse: 40896.6328125, kl_div: 11491.7177734375\n",
            "Epoch [6/50] Step [940/1702] loss: 47937.984375 rmse: 37928.4765625, kl_div: 10009.5078125\n",
            "Epoch [6/50] Step [960/1702] loss: 52503.078125 rmse: 41133.75, kl_div: 11369.330078125\n",
            "Epoch [6/50] Step [980/1702] loss: 52810.1953125 rmse: 41942.87109375, kl_div: 10867.322265625\n",
            "Epoch [6/50] Step [1000/1702] loss: 53240.65625 rmse: 41600.09375, kl_div: 11640.560546875\n",
            "Epoch [6/50] Step [1020/1702] loss: 50929.5234375 rmse: 41024.0078125, kl_div: 9905.5166015625\n",
            "Epoch [6/50] Step [1040/1702] loss: 51584.76171875 rmse: 40895.32421875, kl_div: 10689.4375\n",
            "Epoch [6/50] Step [1060/1702] loss: 51849.23046875 rmse: 41309.8203125, kl_div: 10539.41015625\n",
            "Epoch [6/50] Step [1080/1702] loss: 49547.4921875 rmse: 39526.265625, kl_div: 10021.224609375\n",
            "Epoch [6/50] Step [1100/1702] loss: 51477.59375 rmse: 40714.0078125, kl_div: 10763.5849609375\n",
            "Epoch [6/50] Step [1120/1702] loss: 49320.6875 rmse: 39062.71875, kl_div: 10257.966796875\n",
            "Epoch [6/50] Step [1140/1702] loss: 50240.9140625 rmse: 39307.8125, kl_div: 10933.1015625\n",
            "Epoch [6/50] Step [1160/1702] loss: 51145.31640625 rmse: 40785.02734375, kl_div: 10360.2890625\n",
            "Epoch [6/50] Step [1180/1702] loss: 50184.765625 rmse: 39763.125, kl_div: 10421.640625\n",
            "Epoch [6/50] Step [1200/1702] loss: 49117.9609375 rmse: 38802.84375, kl_div: 10315.1171875\n",
            "Epoch [6/50] Step [1220/1702] loss: 48837.7265625 rmse: 38497.9921875, kl_div: 10339.734375\n",
            "Epoch [6/50] Step [1240/1702] loss: 50746.97265625 rmse: 41030.59375, kl_div: 9716.3779296875\n",
            "Epoch [6/50] Step [1260/1702] loss: 49822.66796875 rmse: 40074.6640625, kl_div: 9748.00390625\n",
            "Epoch [6/50] Step [1280/1702] loss: 50327.953125 rmse: 40090.8046875, kl_div: 10237.146484375\n",
            "Epoch [6/50] Step [1300/1702] loss: 48728.98046875 rmse: 38058.1171875, kl_div: 10670.8642578125\n",
            "Epoch [6/50] Step [1320/1702] loss: 54851.8046875 rmse: 43672.59375, kl_div: 11179.212890625\n",
            "Epoch [6/50] Step [1340/1702] loss: 51278.5234375 rmse: 41175.3359375, kl_div: 10103.1865234375\n",
            "Epoch [6/50] Step [1360/1702] loss: 143052.609375 rmse: 44803.3515625, kl_div: 98249.2578125\n",
            "Epoch [6/50] Step [1380/1702] loss: 50505.2890625 rmse: 40043.265625, kl_div: 10462.025390625\n",
            "Epoch [6/50] Step [1400/1702] loss: 49235.515625 rmse: 39633.87890625, kl_div: 9601.63671875\n",
            "Epoch [6/50] Step [1420/1702] loss: 51962.01171875 rmse: 41416.54296875, kl_div: 10545.4677734375\n",
            "Epoch [6/50] Step [1440/1702] loss: 51584.796875 rmse: 40210.078125, kl_div: 11374.716796875\n",
            "Epoch [6/50] Step [1460/1702] loss: 53747.890625 rmse: 42810.90234375, kl_div: 10936.986328125\n",
            "Epoch [6/50] Step [1480/1702] loss: 52531.4609375 rmse: 40838.8828125, kl_div: 11692.5791015625\n",
            "Epoch [6/50] Step [1500/1702] loss: 54650.14453125 rmse: 41556.7265625, kl_div: 13093.41796875\n",
            "Epoch [6/50] Step [1520/1702] loss: 49053.41796875 rmse: 38755.73828125, kl_div: 10297.6806640625\n",
            "Epoch [6/50] Step [1540/1702] loss: 51970.390625 rmse: 40782.4375, kl_div: 11187.953125\n",
            "Epoch [6/50] Step [1560/1702] loss: 47403.578125 rmse: 36989.296875, kl_div: 10414.279296875\n",
            "Epoch [6/50] Step [1580/1702] loss: 57070.671875 rmse: 45166.4921875, kl_div: 11904.1806640625\n",
            "Epoch [6/50] Step [1600/1702] loss: 51819.5390625 rmse: 40443.203125, kl_div: 11376.3359375\n",
            "Epoch [6/50] Step [1620/1702] loss: 54906.45703125 rmse: 42891.2890625, kl_div: 12015.16796875\n",
            "Epoch [6/50] Step [1640/1702] loss: 52722.4765625 rmse: 41973.96875, kl_div: 10748.509765625\n",
            "Epoch [6/50] Step [1660/1702] loss: 54939.3359375 rmse: 43695.64453125, kl_div: 11243.69140625\n",
            "Epoch [6/50] Step [1680/1702] loss: 53650.9375 rmse: 42237.5859375, kl_div: 11413.349609375\n",
            "Epoch [6/50] Step [1700/1702] loss: 51388.05078125 rmse: 40471.453125, kl_div: 10916.5966796875\n",
            "Epoch [7/50] Step [20/1702] loss: 49931.53125 rmse: 39947.1328125, kl_div: 9984.3984375\n",
            "Epoch [7/50] Step [40/1702] loss: 51109.34375 rmse: 40641.8046875, kl_div: 10467.541015625\n",
            "Epoch [7/50] Step [60/1702] loss: 52808.3671875 rmse: 40942.12109375, kl_div: 11866.244140625\n",
            "Epoch [7/50] Step [80/1702] loss: 50469.98046875 rmse: 40100.03515625, kl_div: 10369.9462890625\n",
            "Epoch [7/50] Step [100/1702] loss: 52633.9375 rmse: 40751.3046875, kl_div: 11882.6328125\n",
            "Epoch [7/50] Step [120/1702] loss: 53598.125 rmse: 41801.6953125, kl_div: 11796.427734375\n",
            "Epoch [7/50] Step [140/1702] loss: 51691.328125 rmse: 41253.53515625, kl_div: 10437.794921875\n",
            "Epoch [7/50] Step [160/1702] loss: 50722.7421875 rmse: 41057.609375, kl_div: 9665.134765625\n",
            "Epoch [7/50] Step [180/1702] loss: 51208.6171875 rmse: 40290.1015625, kl_div: 10918.517578125\n",
            "Epoch [7/50] Step [200/1702] loss: 3.699306963391667e+29 rmse: 46149.5546875, kl_div: 3.699306963391667e+29\n",
            "Epoch [7/50] Step [220/1702] loss: 7096813.0 rmse: 45041.21484375, kl_div: 7051772.0\n",
            "Epoch [7/50] Step [240/1702] loss: 62496.0546875 rmse: 45557.5546875, kl_div: 16938.498046875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-d352d656704c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMCEOsQ6t4xV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "af99699d-9a7f-4433-8dbc-5a4b3a9fe161"
      },
      "source": [
        "print(loss)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-9c7d9083178b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;31m# All strings are unicode in Python 3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_str_intern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str_intern\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    349\u001b[0m                     \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                     \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_formatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimag_formatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mnonzero_finite_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mtensor_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnonzero_finite_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVX8uEA-SFNe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "f1baa769-a242-46b5-c631-ceb809d6b5c8"
      },
      "source": [
        "tags = ['Buildings', 'Forests', 'Mountains', 'Glacier', 'Street', 'Sea']\n",
        "\n",
        "with torch.no_grad():\n",
        "  # img[0], new_img[0], label[0]\n",
        "  if device == 'cuda': img, new_img = img.cpu(), new_img.cpu()\n",
        "  show_original_set = img.view(img.size(0),28, 28).numpy()\n",
        "  show_gen_set = new_img.view(new_img.size(0), 28, 28).numpy()\n",
        "\n",
        "  for i in range(8):\n",
        "    show_original = show_original_set[i]\n",
        "    show_gen = show_gen_set[i]\n",
        "\n",
        "    plt.subplot(2, 8, i+1)\n",
        "    plt.title('ori')\n",
        "    plt.imshow(show_original, cmap='gray')\n",
        "    plt.subplot(2, 8, i + 9)\n",
        "    plt.title('gen')\n",
        "    plt.imshow(show_gen, cmap = 'gray')\n",
        "    plt.axis(False)\n",
        "    \n",
        "  plt.suptitle('Epoch: {}'.format(epoch+1), fontsize=16)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-5568ee441bd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;31m# img[0], new_img[0], label[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mshow_original_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mshow_gen_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    }
  ]
}